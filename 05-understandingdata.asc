:chapnum: 05
:figure-number: 00

== ENTENDER LOS DATOS

image::figs/incoming/05-00-cover.png[float="none",role="informal"]

++++
<?dbfo-need height="1in"?>
++++


Una vez que tiene sus datos, ¿qué hace con ellos? ¿Qué debe buscar? 
¿Qué herramientas debe usar? Esta sección comienza con algunas ideas acerca de
cómo mejorar su conocimiento del manejo de datos, 
consejos para trabajar con cifras y estadísticas, 
y cosas a tener en cuenta cuando trabaja con conjuntos de datos desordenados, 
imperfectos y a menudo poco documentados. 
Podemos luego aprender a obtener historias de los datos, 
cuáles son las herramientas preferidas de los periodistas de datos, 
y cómo usar la visualización de datos 
para que ayude a entender el tópico en cuestión.

=== Aprenda a manejar datos con 3 pasos simples


Así como la alfabetización refiere a “la capacidad de leer para conocer, 
escribir de modo coherente y pensar críticamente acerca de material impreso”, 
la alfabetización en materia de datos es la capacidad de manejar datos 
para conocer, producir coherentemente y pensar críticamente acerca de datos. 
La alfabetización en materia de datos incluye la alfabetización estadística, 
pero también comprende cómo trabajar con grandes conjuntos de datos, cómo fueron producidos, 
como relacionar varios conjuntos de datos y como interpretarlos.

[[FIG051]]
.http://www.flickr.com/photos/jdhancock/3386035827/[Cavar en los datos] (photo by JDHancock)
image::figs/incoming/05-MM.jpg[float="none"]

++++
<?dbfo-need height="1in"?>
++++

Poynter News University ofrece clases de http://www.newsu.org/courses/math-journalists[matemática para periodistas] 
que ayudan a dominar conceptos tales como cambios porcentuales y promedios. 
Es interesante que estos conceptos se enseñen simultáneamente cerca de las oficinas de Poynter, 
en escuelas de Florida a estudiantes de quinto grado (10-11 años), 
como lo atestigua http://bit.ly/k12-courses[la currícula].

Que los periodistas necesiten ayuda con temas matemáticos normalmente vistos
antes de la escuela secundaria muestra lo lejos que están las redacciones 
de saber manejar datos. Esto es un problema. 
¿Cómo puede una periodista hacer uso de una cantidad de cifras
sobre cambio climático si no sabe lo que significa un intervalo de confianza? 
¿Cómo puede un periodista de datos escribir una historia sobre distribución 
del ingreso si no sabe la http://bit.ly/karenberger-mean-median[diferencia entre media y mediana]?

Una periodista por cierto no necesita tener un título en estadística para ser
más eficiente en el manejo de los datos. Enfrentada a las cifras, 
unos pocos trucos simples pueden ayudarla a armar una historia mucho mejor. 
Como dice el profesor del Instituto Max Planck, Gerd Gigerenzer, tener 
mejores herramientas no permitirá hacer mejor periodismo 
si éstas no son utilizadas con visión.
Aunque no tenga ningún conocimiento de matemática o estadísticas, 
puede convertirse fácilmente en una periodista de datos experimentada
haciendo 3 preguntas muy simples.

==== 1. ¿Cómo se obtuvieron los datos?

==== Sorprendente crecimiento del PBI

La manera más fácil de darse aires con datos espectaculares es fabricarlos. 
Suena obvio, pero datos tan comúnmente comentados como las cifras del PBI
bien pueden ser falsos. El ex embajador británico Craig Murray 
informa en su libro, Asesinato en Samarcanda, que las tasas de crecimiento 
en Uzbekistán están sujetas a intensas negociaciones entre el gobierno local 
y entes internacionales. Dicho de otro modo, no tienen nada que ver con la economía local.

El PBI es usado como el principal indicador porque los gobiernos tienen que 
controlar su principal fuente de ingresos: el IVA. 
Cuando un gobierno no se financia con el IVA, 
o cuando no informa públicamente de su presupuesto, 
no tiene motivos para recoger datos sobre el PBI y le vendrá mejor inventarlos.

==== El crimen siempre está en aumento 

“El crimen en España creció un 3%”, http://bit.ly/elpais-numeracy[escribe El País]. 
Bruselas es presa de un aumento del crimen de extranjeros ilegales y drogadictos, http://bit.ly/rtl-numeracy[escribe RTL]. 
Este tipo de de informes basados en estadísticas recogidas por la policía 
es común, pero no nos dice gran cosa sobre la violencia.

Podemos confiar en que dentro de la Unión Europea los datos no son falsificados. 
Pero el personal policial responde a incentivos. 
Cuando el desempeño está ligado a la tasa de esclarecimiento, por ejemplo, 
los policías tienen un incentivo para informar lo más posible de incidentes
que no requieren investigación. Uno de tales crímenes es el de fumar marihuana. 
Esto explica por qué los crímenes relacionados con las drogas en Francia
se multiplicaron por 4 en los últimos 15 años, 
mientras que el consumo se mantuvo constante.

==== Qué se puede hacer

Cuando dude de la credibilidad de una cifra, verifíquela, tal como lo haría
si se tratara de una declaración  de un político. En el caso uzbeco, una 
llamada a alguien que haya vivido allí un tiempo basta (“¿Es cierto que 
el país es 3 veces más rico que en 1995, como muestran las cifras oficiales?”).

Para los datos policiales, los sociólogos a menudo realizan estudios de victmización,
en los que preguntan a la gente si es víctima de crímenes. Estos estudios son 
mucho menos volátiles que los datos policiales. Quizás ese sea el motivo por el que
no se los destaca en los medios.

Otros tests permiten evaluar la credibilidad de los datos, tales como la ley 
de Benford, pero ninguno de ellos suplanta su pensamiento crítico.

==== 2. ¿Qué se puede aprender de ello?

==== El riesgo de esclerosis múltiple aumenta al doble cuando se trabaja de noche

Sin duda cualquier alemana que no esté loca dejaría de trabajar de noche luego de http://bit.ly/dmsg-numeracy[leer este titular]. 
Pero el artículo no nos dice cuál es el riesgo realmente.

Tome 1000 alemanes. Solo uno tendrá EM. Si todos estos 1000 alemanes trabajaran
de noche, el número de pacientes de EM se iría a 2. El riesgo adicional 
de tener EM trabajando de noche es 1 en 1000, no 100%. Sin duda esta información
es más útil al ponderar si aceptar un empleo. 

==== En promedio, 1 de cada 15 europeos es totalmente analfabeto

Este titular asusta. Además es cierto. Entre los 500 millones de europeos, 
36 millones probablemente no saben leer. Agreguemos que 36 millones también 
tienen menos de 7 años; http://bit.ly/eurostat-numeracy[datos de Eurostat].

Cuando escriba sobre un promedio, siempre piense: ¿Un promedio de qué? 
¿La población de referencia es homogénea? Los patrones de distribución desigual
explican por qué la mayoría de la gente maneja mejor que el promedio, por ejemplo.
Mucha gente tiene cero o solo un accidente en toda su vida. Unos pocos conductores
irresponsables tienen muchos, lo que hace que el número promedio de accidentes 
sea mucho más elevado de lo que es la experiencia de la mayoría de la gente. 
Lo mismo vale para la distribución del ingreso: la mayoría de la gente gana menos que el promedio.

==== Qué puede hacer

Siempre tome en cuenta la distribución y la tasa base. Verificar el media y la mediana 
así como la moda (el valor más frecuente en la distribución) le ayuda a 
interpretar los datos. Conocer el orden de magnitud hace más fácil contextualizar,
como en el ejemplo de EM. Finalmente, informar en base a frecuencias naturales
(1 de cada 100) es mucho más fácil de entender para los lectores 
que usar porcentuales (1%).

==== 3. ¿En qué medida es confiable la información?

===== El problema del tamaño de la muestra

“80% insatisfecho con el sistema judicial”, dice una encuesta 
de la que se informa en http://bit.ly/diariodenavarra[el Diario de Navarra] con sede en Zaragoza.
¿Cómo se puede extrapolar de 800 encuestados a 46.000.000 de españoles? 
Sin duda esto es poco serio.

Cuando se investiga una gran población (más de unos pocos miles) rara vez 
se necesita más que un millar de encuestados para lograr un margen de error 
de menos del 3%. Significa que si fuera a rehacer la encuesta con una muestra
totalmente distinta, 19 veces de 20 las respuestas que recibiría estarían dentro
del intervalo de 3 puntos porcentuales del valor encontrado, comparado con 
lo que hubiera sucedido si entrevistaba a todas las personas.

===== Tomar té reduce el riesgo de infarto

Los artículos acerca de los beneficios de tomar té son comunes. http://bit.ly/welt-tea[Este artículo] 
breve en Die Welt que dice que el té reduce el riesgo de infarto del miocardio 
no es la excepción. Si bien los efectos del té son estudiados seriamente por algunos,
muchas piezas de investigación no toman en cuenta factores de estilo de vida,
tales como dieta, ocupación, o deportes.

En la mayoría de los países, el té es la bebida de las clases altas preocupadas
por la salud. Si los investigadores no toman en cuenta los factores de estilo
de vida en sus estudios sobre el té, no nos dicen más que “los ricos son más 
sanos y probablemente toman té”.

===== Lo que puede hacer

La matemática que es la base de las correlaciones y los márgenes de error en 
los estudios sobre el té es por cierto correcta, al menos la mayoría de 
las veces. Pero si los investigadores no buscan correlaciones (por ejemplo, 
tomar té se correlaciona con hacer deporte), sus resultados son de escaso valor.
Como periodista, tiene poco sentido cuestionar los resultados numéricos 
de un estudio, tales como el tamaño de la muestra, a menos que 
haya serias dudas al respecto. Sin embargo, es fácil de ver si los investigadores 
no tomaron en cuenta elementos relevantes de información.


&mdash; _Nicolas Kayser-Bril, Journalism++_

=== Consejos para trabajar con cifras en las noticias

* El mejor consejo para manejar datos es que lo disfrute. Los datos pueden parecer
algo intimidantes. Pero si se deja intimidar no llegará a nada. Trátelos como
algo para jugar y explorar y a menudo entregarán secretos e historias 
con sorprendente facilidad. De modo que manéjelos de manera simple, 
como lo hace con otras evidencias, sin temor ni parcialidad. En particular, 
piense en esto como un ejercicio de su imaginación. Sea creativo pensando en 
las historias alternativas que podrían ser coherentes con los datos y 
los explican mejor, luego póngalas a prueba con más evidencias. 
“¿Qué otra historia podría explicar esto?”, puede ser una buena pregunta para 
pensar cómo esta cifra evidentemente grande o equivocada, esta clara prueba de
esto o aquello, podría no ser nada por el estilo.

* No confunda el escepticismo respecto de los datos con cinismo. El escepticismo
es bueno; el cinismo simplemente es darse por vencido. Si cree en el periodismo
de datos (y probablemente es así o no estaría leyendo este libro), entonces debe
creer que los datos tienen algo mucho mejor que ofrecer que las mentiras de 
caricatura o los datos de titulares impactantes. Los datos a menudo nos dan conocimiento profundo, si se los usa cuidadosamente. No necesitamos ser cínicos ni ingenuos, sino estar alertas.

* Si le digo que se bebe más durante la recesión, podría decirme que se debe a 
que todos están deprimidos. Si le digo que se bebe menos, podría decirme que 
es porque nadie tiene plata. Dicho de otro modo, lo que digan los datos no 
incide en la interpretación que usted esté decidido a hacer, a saber, que las
cosas están muy mal no importa lo que suceda con la bebida. Si aumenta, 
es malo; si se reduce, es malo. La cuestión aquí es que si usted cree en 
los datos, trate de dejar que hablen antes de imponerles su propio estado de
ánimo, creencias o expectativas. Hay tantos datos que a menudo podría encontrar
confirmación de sus creencias previas si busca un poco. Dicho de otro modo, 
el periodismo de datos, al menos para mí, agrega poco valor si usted no tiene
la mente abierta. Es solo objetivo en la medida que usted lo hace objetivo y 
no en virtud de que se basa en números.

* La incertidumbre no es problema. Asociamos las cifras con la autoridad y 
la certidumbre. Muy a menudo la respuesta es que no hay respuesta, o la respuesta
es la mejor que tenemos pero no es para nada precisa. Creo que debemos decir 
estas cosas. Si eso suena como una buena manera de matar una historia, sostendría
que es una gran manera de generar nuevos interrogantes. Del mismo modo, a menudo
puede haber más de un modo legítimo de ordenar los datos. 
Los números no tienen que ser ciertos o falsos.

* La investigación es una historia. La historia de cómo intentó descubrir algo,
al avanzar de un elemento de evidencia a otro, puede ser excelente periodismo 
y esto se aplica especialmente a la evidencia de los datos, donde rara vez 
basta con una cifra. Distintas fuentes dan nuevos ángulos de interpretación,
nuevas ideas y una comprensión enriquecida. Me pregunto si estamos demasiado
preocupados por ganar autoridad y darle la respuesta a la gente, hasta el punto
de que desaprovechamos un recurso, que es mostrar nuestra investigación.

++++
<?dbfo-need height="1in"?>
++++

* Las mejores preguntas son las de siempre: ¿eso realmente es un número grande? 
¿De dónde salió? ¿Está seguro de que cuenta lo que usted cree que cuenta? 
Estos por lo general son solo incentivos para mirar lo que rodea a los datos, 
las cosas que quedaron de lado por mirar un solo número, las complicaciones 
de la vida real, la amplia gama de otras comparaciones posibles con relación 
al tiempo, el grupo o la geografía; en síntesis, el contexto.

&mdash; _Michael Blastland, freelance journalist_

=== Pasos básicos para trabajar con datos

Hay al menos 3 conceptos clave que tiene que entender cuando comience 
un proyecto de datos:

*	Los pedidos de datos deben comenzar con una lista de preguntas que quiere contestar
*	Los datos a menudo vienen sucios y hay que limpiarlos
*	Los datos pueden tener aspectos sin documentar

[[FIG052]]
.Datos desordenados
image::figs/incoming/05-MM.png[scale="89",float="none"]

==== Sepa para qué preguntas quiere respuestas

En muchos sentidos, trabajar con datos es como entrevistar una fuente en vivo.
Usted le hace preguntas a los datos y logra que revelen las respuestas. Pero así
como una fuente solo puede dar respuestas respecto de las cuales tiene información,
un conjunto de datos solo puede responder preguntas para las que tiene los registros
adecuados y las variables correspondientes. Esto significa que usted debe considerar
cuidadosamente qué preguntas quiere responder antes de obtener datos. Básicamente
se trabaja hacia atrás. Primero, la lista de afirmaciones basadas en datos que
quieres presentar en su historia. Luego decida qué variables y evidencias tendrá
que obtener y analizar para hacer esas afirmaciones.

Considere  un ejemplo que tiene que ver con los informes de crímenes locales.
Digamos que quiere escribir una historia que analice los patrones del crimen
en su ciudad, y las cosas que quiere decir tienen que ver con la hora del día
y los días de la semana en los que es más común que se den ciertos tipos de crímenes,
así como en qué zonas de la ciudad se concentran varias categorías de crímenes. 

Tendría que advertir que su pedido de datos tiene que incluir la fecha y 
el momento en que cada crimen fue informado, el tipo de crimen (asesinato,
robo, asalto, etc.), así como la dirección de donde se dio el crimen. De modo
que fecha, hora, categoría de crimen y dirección son las variables mínimas que
necesita para responder a esas preguntas.

Pero sea consciente de que hay una cantidad de preguntas potencialmente interesantes
que este conjunto de datos de 4 variables no puede  responder, como la raza y
el género de las víctimas, o el valor total de la propiedad robada, o qué agentes
son más productivos en cuanto a lograr arrestos. Además quizás solo pueda conseguir
los registros de cierto período, como los últimos 3 años, lo que quiere decir que
no podría saber si los patrones del crimen han cambiado respecto de un período
más prolongado. Esas preguntas pueden quedar por fuera del plan de su historia,
y eso no es problema. Pero usted no querrá meterse en su análisis de los datos
y de pronto advertir que necesita saber qué porcentaje de los crímenes en distintas
zonas de la ciudad son resueltos con arrestos.

Una lección aquí es que a menudo es buena idea pedir todas las variables y 
registros en la base de datos, en vez del subconjunto que respondería a las
preguntas para la historia inmediata. (de hecho, obtener todos los datos 
puede ser más barato que obtener un subconjunto, si tiene que pagar a la 
agencia por la programación necesaria para producir el subconjunto.) 
Siempre puede armar el subconjunto de datos por su cuenta y tener acceso al
conjunto de datos completo le permitirá  responder nuevas preguntas que pueden
surgir durante su trabajo e incluso producir nuevas ideas para la continuación
de la historia. Puede ser que las leyes de confidencialidad u otras políticas
signifiquen que algunas variables, tales como las identidades de las víctimas
o los nombres de informantes confidenciales, no puedan difundirse. Pero incluso 
una base de datos parcial es mejor que nada, siempre que usted entienda qué preguntas
puede o no contestar la base de datos.

==== Limpiar datos no normalizados

Uno de los mayores problemas en el trabajo con bases de datos es que a menudo
usará datos para análisis que han sido recogidos por motivos burocráticos. 
El problema es que el nivel exigido de precisión es bastante diferente.

Por ejemplo, una función clave de un sistema de bases de datos para la justicia
penal es asegurarse que el acusado Jones sea traído de la cárcel al juzgado 
para estar frente la juez Smith en el momento de su audiencia. Para ese propósito
no importa mucho si la fecha de nacimiento de Jones es incorrecta, o que esté
mal escrito el nombre de la calle en la que vive o siquiera si la inicial de
su segundo nombre sea equivocada. En general el sistema aún puede usar este 
registro imperfecto para llevar a Jones al juzgado de Smith a la hora indicada.

Pero tales errores pueden complicar los esfuerzos del periodista  por descubrir
patrones en la base de datos. Por ese motivo, la primera gran tarea que debe 
encarar cuando obtiene un nuevo conjunto de datos es examinar hasta donde tiene
problemas y solucionarlos. Una manera rápida de buscar datos no normalizados es
crear tablas de frecuencias de las variables por categoría, las que uno esperaría
que tengan un número relativamente pequeño de valores diferentes. (Cuando use 
Excel, por ejemplo, usted puede usar Filtros o Tablas Dinámicas para cada variable
categórica.)

Tomemos por caso “género”, un ejemplo simple. Usted puede descubrir que el campo
de Género incluye cualquier mezcla de valores como estos: Masculino, Femenino,
M, F, 1, 0, MASCULINO, FEMENINO, etc., incluyendo errores de escritura como 
“Femeno”. Para hacer un análisis de género adecuado debe estandarizar – quizás
se decida por M y F- y luego cambiar todas las variaciones para que coincidan
con los estándares. Otra base de datos común con este tipo de problemas es la
de los registros financieros de campañas electorales de Estados Unidos, donde
en el campo de Ocupación puede dar las distintas variantes de abogado en inglés
(Lawyer, Attorney, Atty, Counsel, Trial lawyer y muchas otras) además de los 
errores de escritura; nuevamente el truco es estandarizar los títulos de 
ocupación en una lista de posibilidades más corta.

La limpieza de los datos se vuelve aún más problemática cuando se trabaja con 
nombres. ¿“Joseph T. Smith”, “Joseph Smith”, “J.T. Smith”, “Jos. Smith” y 
“Joe Smith” son todos la misma persona? Quizás haya que mirar otras variables
como dirección o fecha de nacimiento, o hacer una investigación aún más profunda
en otros registros, para decidir. Pero herramientas como Google Refine pueden
hacer que la limpieza y estandarización sean más rápidas y menos tediosas.

.Datos sucios
****
Gracias a las leyes de registro público por lo general fuertes en Estados Unidos,
obtener datos aquí no es un problema tan grande como en muchos otros países. 
Pero una vez que los tenemos, aún quedan los problemas de trabajar con datos 
que han sido recogidos por motivos burocráticos y no con propósitos analíticos.
Los datos a menudo vienen “sucios”, con valores que no están estandarizados. 
Varias veces he recibido datos que no se corresponden con el supuesto diagrama
del archivo y el diccionario de datos que los acompañan. Algunas entidades 
insistirán en darle los datos en formatos poco útiles como .PDF, que tienen 
que ser convertidos. Problemas como estos hacen que uno lo aprecie cuando 
ocasionalmente recibe un conjunto de datos sin complicaciones.

&mdash; _Steve Doig, Walter Cronkite School of Journalism, Arizona State University_
****

==== Los datos pueden tener aspectos no documentados

La Piedra de Roseta de cualquier base de datos es el llamado diccionario de 
datos. Comúnmente, este archivo (puede ser texto PDF o incluso una hoja de 
cálculo) le dirá cómo está formateado el archivo de los datos (texto delimitado,
texto de ancho fijo, Excel, dBase, etc.), el orden de las variables, los nombres
de cada variable y el tipo de datos de cada variable (hilo de texto, entero, 
decimal, etc.). Usted usará esta información para que lo ayude a importar 
adecuadamente el archivo de datos al software de análisis que piensa usar 
(Excel, Access, SPSS, Fusion Tables, distintas variantes de SQL, etc.)

El otro elemento clave de un diccionario de datos es una explicación de los códigos
que puedan usar variables particulares. Por ejemplo, género puede estar codificado
de tal modo que “1=Masculino” y “0=Femenino”. Los crímenes pueden estar codificados
de acuerdo a los números estatutarios de su jurisdicción para cada tipo de crimen.
Los registros de tratamientos hospitalarios pueden usar cualquiera de los cientos
de códigos de 5 dígitos existentes para el diagnóstico de las enfermedades por
las que está tratando a un paciente. Sin el diccionario de datos, estos conjuntos
de datos serían difíciles o incluso imposibles de analizar adecuadamente.

Pero incluso contando con un diccionario de datos puede haber problemas.
Un ejemplo de tales problemas es lo que le sucedió a periodistas del Miami Herald
en Florida hace algunos años, cuando estaban haciendo el análisis de los variados
castigos que distintos jueces estaban imponiendo a gente arrestada por manejar
ebria e intoxicada. Los periodistas obtuvieron los registros de condenas del sistema
judicial y analizaron las cifras con las 3 variables distintas de castigos en 
el diccionario de datos: cantidad de tiempo en prisión, cantidad de tiempo 
detenido y cantidad de multa. Las cifras variaban bastante entre los jueces, 
dando a los periodistas evidencias para una historia acerca de que algunos jueces 
eran duros y otros más permisivos.

Pero para todos los jueces, en alrededor del 1-2 por ciento de los casos no había
tiempo de prisión, ni de detención, ni multa. Por lo que el cuadro que mostraba
los patrones de condenas de cada juez incluía una cantidad pequeña de casos
como “Sin castigo”, casi como una nota al margen. Cuando la historia y el cuadro
se publicaron, los jueces aullaron de indignación, diciendo que el Herald los
acusaba de violar una ley estatal que exige que cualquiera condenado por manejar
borracho sufra castigo.

Por lo que los periodistas volvieron a la oficina del empleado de la corte que
les había dado el archivo de datos y le preguntaron qué era lo que había causado
el error. Se les dijo que los casos en cuestión involucraban a acusados indigentes
que eran arrestados por primera vez. Normalmente se les hubiera impuesto una multa
pero no tenían dinero. Por lo que los jueces los condenaban a servicios comunitarios,
tales como limpiar la basura en los caminos. Resultó que la ley que requería 
el castigo había sido aprobada después de que fuera creada la estructura de la
base de datos. Por lo que los empleados de la corte sabían que en los datos los
ceros en las 3 variables de prisión-detención-multa significaban servicio comunitario.
Sin embargo, esto no aparecía en el diccionario de datos y por tanto el Herald 
tuvo que publicar la correspondiente rectificación.

La lección en este caso es que siempre hay que preguntar al ente que le da los
datos si hay elementos no documentados de los mismos, lo que podría significar
códigos nuevos que no están incluidos en el diccionario de datos, cambios en el
ordenamiento del archivo, o cualquier otra cosa. Además examine siempre los 
resultados de su análisis y pregúntese: “¿Esto tiene sentido?” Los periodistas 
del Herald estaban armando el cuadro apurados por el plazo de entrega y estaban
tan concentrados en los niveles de castigo promedio de cada juez, que no prestaron
atención a los pocos casos que parecían no tener castigo. Debieron haberse preguntado
si tenía sentido que todos los jueces aparentemente estuvieran violando la ley estatal,
aunque más no fuera en mínima medida.

&mdash; _Steve Doig,  Walter Cronkite School of Journalism, Arizona State University_

++++
<?dbfo-need height="2in"?>
++++

.Datos mezclados, ocultos y faltantes
****

Recuerdo una situación graciosa en la que tratamos de acceder a los datos de
Hungría sobre subsidios agropecuarios de la UE: estaban todos allí, pero en un
documento PDF excesivamente pesado y mezclado con datos sobre subsidios 
agropecuarios nacionales. Nuestros programadores tuvieron que trabajar horas 
antes de que los datos pudieran ser utilizados.

También tuvimos una experiencia bastante interesante con datos sobre subsidios
de pesca de la UE, que los entes nacionales encargados de los pagos de los 27 
estados miembros están obligados a dar a conocer. Esto está tomado de un informe
que escribimos http://bit.ly/alfter-eu27[sobre el tema]: “En el Reino Unido, 
por ejemplo, el formato de los datos varía de páginas de búsqueda HTML muy fáciles 
de usar hasta resúmenes en PDF o incluso listas de receptores en formatos variados
disimulados al final de declaraciones de prensa. Todo esto de un solo estado 
miembro. Mientras tanto, en Alemania y Bulgaria se publican listas vacías. 
Tienen los encabezados apropiados, pero sin datos”.

&mdash; _Brigitte Alfter, Journalismfund.eu_
****

=== La pieza de pan de £ 32

Una historia para el Wales On Sunday acerca de cuánto gasta el gobierno galés
en órdenes para productos libre de gluten contenía un titular que indicaba que
pagaba £32 por una pieza de pan. Pero en realidad eran 11 piezas que costaban
£2,82 cada una.

Los datos, tomados de una respuesta por escrito de la Legislatura Galesa y un
informe estadístico del Servicio de Salud de Gales, estaban presentados con el
formato del costo por cada ítem de las órdenes. Sin embargo en el diccionario 
de datos no daban ninguna definición adicional de lo que podría ser un ítem de
orden o cómo podría definirlo una columna de cantidades por separado.

La suposición era que se refería a un ítem individual –es decir, una pieza de pan-
en vez de lo que era en realidad, varias piezas. 

Nadie, ni la gente que dio la respuesta por escrito ni la oficina de prensa, 
plantearon la cuestión de la cantidad hasta el lunes posterior a la publicación
de la historia.

Por lo que no debe dar por supuesto que las notas de soporte de los datos oficiales
ayudarán a explicar qué información se presenta, o que la gente responsable de
los datos advertirá que la información no es clara, incluso cuando usted les 
presente una suposición equivocada.

Por lo general los diarios quieren cosas que produzcan buenos titulares, de modo que,
a menos que algo contradiga evidentemente una interpretación, por lo general es más
fácil aceptar lo que permite hacer un buen titular y no investigar demasiado, 
con el riesgo de que se hunda la historia, especialmente a la hora del cierre.

[[FIG053]]
.Las órdenes de pan libre de gluten le cuestan a los contribuyentes (WalesOnline)
image::figs/incoming/05-AA.png[float="none"]

Pero los periodistas tienen la responsabilidad de verificar las afirmaciones 
ridículas, aunque signifique que esto hace caer la noticia.

&mdash; _Claire Miller, WalesOnline_


=== Empiece por los datos, termine con una historia

Para atraer a sus lectores tiene que poder darles una cifra en los titulares 
que los haga prestar atención. Casi se debiera poder leer la historia sin tener
que saber que se basa en un conjunto de datos. Hágala interesante y recuerde quién
es su público.

Un ejemplo de esto puede encontrarse en un proyecto del Bureau of Investigative Journalism que utiliza 
el  http://bit.ly/ec-fts[Sistema de Transparencia Financiera] de la Comisión de la UE.
La historia se construyó con el conjunto de datos teniendo en mente interrogantes
específicos.

Investigamos en los datos con términos clave tales como “coctel”, “golf” y 
“días de descanso”. Esto nos permitió establecer lo que la Comisión había gastado
en estos ítems y esto planteó numerosas preguntas e historias para seguir. 

Pero los términos clave no siempre le dan lo que quiere; a veces tiene que tomarse
un respiro y pensar qué es realmente lo que busca. Durante este proyecto también
queríamos descubrir cuánto gastan los comisionados en viajes en jet privado pero
como el conjunto de datos no contenía la frase “jet privado” tuvimos que obtener
el nombre de sus proveedores de viajes por otros medios. Una vez que tuvimos el
nombre del proveedor de servicios de la Comisión, “Abelag”, pudimos buscar en
los datos cuánto se estaba gastando en servicios provistos por Abelag.

Con este enfoque teníamos un objetivo claramente definido para investigar con
los datos: encontrar una cifra que pudiera proveer un titular; el colorido de
la noticia siguió a ello.

Otro enfoque es comenzar con una lista negra y buscar exclusiones. ¿Una manera
fácil de encontrar historias en los datos es saber qué cosas no debiera encontrar
allí! Un buen ejemplo de cómo esto puede funcionar es ilustrado por el proyecto
en colaboración de Fondos Estructurales de la UE, entre el Financial Times y el
Bureau of Investigative Journalism.

Investigamos los datos basándonos en las reglas de la Comisión respecto de qué
compañías y asociaciones no deben recibir fondos estructurales. Un ejemplo era
el gasto en tabaco y productores de tabaco.

Investigando los datos con los nombres de las compañías, productores y cultivadores
de tabaco, encontramos datos que revelaron que British American Tabaco estaba
recibiendo € 1.500.000 para una planta en Alemania.

Dado que esa financiación violaba las normas de gastos de la Comisión, fue una
manera rápida de encontrar una historia en los datos.

Nunca se sabe lo que uno puede encontrar en un conjunto de datos, así que eche
una mirada. Hay que ser bastante audaz y este enfoque funciona mejor por lo 
general cuando se trata de identificar características evidentes que se verán
con el filtrado (los mayores, los extremos, los más comunes, etc.).

&mdash; _Caelainn Barr, Citywire_

=== Historias basadas en datos

El periodismo de datos a veces puede dar la impresión que principalmente se trata
de la presentación de los datos, tales como visualizaciones que son instrumentos
poderosos que permiten comprender rápidamente algún aspecto de las cifras, o bases
de datos interactivas que permiten a los individuos  buscar lugares como su propia
calle o un hospital. Todo esto puede ser muy valioso, pero al igual que otras 
formas de periodismo, el periodismo de datos también debe ser sobre historias.
¿Qué tipos de historias pueden encontrarse en los datos? Basándome en mi experiencia
en la BBC he armado una lista o “tipología” de distintos tipos de historias basadas 
en datos.

Creo que es útil tener en cuenta esta lista, no solo cuando analiza datos, sino
también en la fase previa, cuando los está buscando (sean datos a disposición del
público o los que exigen presentar pedidos de acceso a la información).

Medición::
  La historia simple; contar o hacer el total: “Los consejos municipales de todo
el país gastaron un total de $x miles de millones en broches de papel el año pasado”.
Pero a menudo es difícil saber si eso es mucho o poco. Para eso se necesita contexto,
lo que puede ser aportado por:

Proporción::
  “El año pasado los consejos municipales gastaron 2/3 de su presupuesto de librería
en broches de papel”

Comparación interna::
  “Los consejos municipales gastan más en broches para papel que en proveer comidas
para personas mayores”.

Comparación externa::
  “El gasto de los consejos en broches de papel el año pasado fue el doble del
presupuesto de la nación de ayuda a otros países”.

También hay otras maneras de explorar los datos de un modo contextual o comparativo:

Cambio a lo largo del tiempo::
  “El gasto de los consejos en broches para papel se ha triplicado en los últimos
 4 años”.

 “Tablas comparativas”::
   Estas a menudo son geográficas o por institución, y debe asegurarse de que
la base de comparación sea justa (por ejemplo, que tome en cuenta el tamaño de
la población local). “El Consejo de Borsetshire gasta más en broches para papel
por cada miembro del personal que cualquier otra municipalidad, con una tasa de
4 veces el promedio nacional”.

O puede dividir los temas de los datos en grupos:

Análisis por categorías::
   “Los consejos dirigidos por el Partido Violeta gastan 50% más en broches de
papel que los controlados por el Partido Amarillo”.

O puede relacionar los factores numéricamente:

Asociación::
   “Los consejos dirigidos por políticos que han recibido aportes de campaña de 
compañías de productos de librería gastan más en broches de papel, con el gasto 
aumentando en promedio £ 100 por cada libra aportada en la campaña”.

++++
<?dbfo-need height="1in"?>
++++

Pero, por supuesto, recuerde que correlación y causa no son la misma cosa.

De modo que si está investigando el gasto en broches de papel, ¿está obteniendo también las siguientes cifras?

	* Gasto total para dar contexto
	* Referencias geográficas/ históricas/de otro tipo para poder dar datos comparativos
	* Los datos adicionales que necesita para asegurarse de que las comparaciones son justas, tales como el tamaño de la población.
	* Otros datos que podrían facilitar un análisis interesante o con los cuales comparar o relacionar el gasto.


&mdash; _Martin Rosenbaum, BBC_

=== Los periodistas de datos debaten sobre sus herramientas preferidas ===

Sssssss. Es el sonido de sus datos descomprimiéndose al abrirse su envoltorio
al vacío. ¿Y ahora qué? ¿Qué busca? ¿Y qué herramientas usa? Pedimos a periodistas
de datos que nos contaran un poco de cómo trabajan con datos. Esto es lo que nos
dijeron:

[quote, Lisa Evans, The Guardian]

____
En el Datablog de The Guardian nos gusta interactuar con nuestros lectores y
permitirles replicar nuestro periodismo de datos rápidamente significa que pueden
desarrollar el trabajo que hacemos y a veces ver cosas que se nos pasaron. Por
lo que cuanto más intuitivas son las herramientas de datos mejor. Tratamos de
elegir herramientas que cualquiera pueda manejar sin tener que aprender un lenguaje
de programación o que requieran fuerte capacitación a un costo elevado.

Por este motivo actualmente usamos mucho productos de Google. Todos los conjuntos
de datos que ordenamos y difundimos aparecen como Google Fusion Tables, lo que
significa que gente que tenga una cuenta de Google puede descargar los datos, 
importarlos a su propia cuenta y hacer sus propios cuadros, ordenar los datos
y crear tablas comparativas, o pueden importar los datos a la herramienta que
prefieran.

Para mapear los datos usamosa Google Fusion Tables. Cuando creamos mapas de calor
en Fusion, compartimos nuestros archivos KML de modo que los lectores puedan
descargar y crear sus propios mapas de calor –quizás agregando más capas de datos
al mapa original del Datablog. El otro aspecto positivo de estas herramientas
de Google es que funcionan con las muchas plataformas que usan nuestros lectores
para acceder al blog, incluyendo PC, celulares y tabletas.

Además de las de  Google Spreadsheets y Google Fusion Tables, usamos otras dos
herramientas en nuestro trabajo cotidiano. La primera es Tableau, para visualizar
conjuntos de datos multidimensionales; y la segunda es ManyEyes, para un análisis
rápido de datos. Ninguna de estas herramientas es perfecta, por lo que seguimos
buscando mejores herramientas de visualización que nuestros lectores puedan disfrutar.
____


[quote, Cynthia O'Murchu, Financial Times]
____
¿Llegaré a ser programador alguna vez? ¡Es muy improbable! Por cierto que no 
creo que todos los periodistas tengan que saber programar. Pero sí creo que es
muy valioso que todos tengan una conciencia general de qué cosas son posibles 
y cómo hablar con programadores.

Si está recién comenzando, camine, no corra. Tiene que persuadir a sus colegas
y editores que trabajar con datos le puede permitir conseguir historias que de
otro modo no tendría y que valen la pena. Cuando adviertan el valor de este enfoque,
puede comenzar a hacer historias y proyectos más complejos.

Mi consejo es aprender Excel y hacer algunas historias simples primero. Comience
por cosas pequeñas y vaya recorriendo el camino hasta el análisis y mapeo de bases
de datos. Se puede hacer tanto en Excel; es una herramienta extremadamente poderosa
y la mayoría de la gente no usa siquiera una mínima parte de su funcionalidad.
Si puede haga un curso de Excel para periodistas, tales como los que ofrece el
Centre for Investigative Journalism.

Con respecto a interpretar datos: no lo tome a la ligera. Tiene que ser detallista.
Preste atención a los detalles y cuestione sus resultados. Tome notas de cómo
procesa los datos y guarde una copia de los datos originales. Es fácil cometer
un error. Siempre hago mi análisis 2 o 3 veces prácticamente desde cero. Incluso
mejor sería conseguir que su editor u otra persona analice los datos por su cuenta
y compare los resultados.
____

[quote, Scott Klein, ProPublica]
____
La capacidad de escribir, instalar y ejecutar software complejo tan rápido como
un periodista puede escribir una historia es algo bastante nuevo. Antes llevaba
mucho más tiempo. Las cosas cambiaron gracias al desarrollo de  bases de desarrollo
rápido de código abierto: Django y Ruby on Rails; ambos se conocieron a mediados
de la década del 2000.

Django, que está construido sobre el lenguaje de programación Python, fue desarrollado
por Adrian Holovaty y un equipo que trabajaba en una redacción, el Lawrence Journal-World
en Lawrence, Kansas. Ruby on Rails fue desarrollado en Chicago por David Heinemeier
Hansson y 37Signals, una compañía de aplicaciones para la red.

Si bien estas plataformas tienen enfoques diferentes del “patrón MVC”, ambas son
excelentes y hacen posible crear aplicaciones para la red rápidamente, incluso
muy complejas. Eliminan parte del trabajo rudimentario en la creación de una
aplicación. Cosas como crear y buscar ítems de la base de datos, y hacer corresponder 
URL con códigos específicos en una aplicación, están incorporados a esas plataformas,
por lo que los diseñadores no necesitan escribir programas o hacer cosas básicas
como esas.

El desarrollo de servicios de provisión de espacio en servidores rápidos de la
red como los Amazon Web Services eliminaron parte de lo que hacía del lanzamiento
de una aplicación un proceso lento.

Aparte de eso, usamos herramientas bastante estándar para el trabajo con datos:
Google Refine y Microsoft Excel para limpiar los datos; SPSS y R para hacer estadísticas;
ArcGIS y QGIS para hacer GIS; Git para el manejo de códigos fuente; TextMate,
Vim y Sublime Text para escribir código; y una mezcla de MySql, PostgreSQL y 
SQL Server para bases de datos. Creamos nuestra propia plataforma de JavaScript 
llamada “Glass” que nos ayuda a crear aplicaciones para usuarios pesadas en 
JavaScript muy rápidamente.
____

[quote, Cheryl Phillips, The Seattle Times]
____
A veces la mejor herramienta es la más simple, es fácil subestimar el poder de
una planilla de cálculo. Pero usar una planilla de cálculo en los tiempos en que
todo funcionaba con DOS me permitió entender una fórmula compleja del acuerdo 
de asociación de los dueños de los Texas Rangers, cuando George W. Bush era uno
de los propietarios claves. Una planilla de cálculo me permite descubrir datos
importantes o errores en cálculos. Puedo escribir líneas de código en algún 
lenguaje de programación (script) para limpieza, normalización y más. Es un 
elemento básico del set de herramientas del periodista de datos.

Dicho eso, mis herramientas favoritas son aún más poderosas: SPSS para análisis
estadístico y mapear programas que me permiten ver patrones geográficos.

____

[quote, Gregor Aisch, Open Knowledge Foundation]
____
Soy fanático de Python. Es un lenguaje de programación de código abierto maravilloso
que es fácil de leer y escribir (por ejemplo, no hay que escribir un punto y
coma después de cada línea). Lo que es más importante, Python tiene una base
tremenda de usuarios y por tanto tiene plugins (llamados paquetes) para todo 
lo que uno necesite.

Considero que Django es algo que los periodistas de datos rara vez necesitan.
Es una plataforma basada en Python para aplicaciones en la red, es decir una 
herramienta para crear aplicaciones grandes en la red con bases de datos. 
Decididamente es demasiado pesado para infografías interactivas pequeñas.

También uso QGis, que es  una herramienta de código abierto con una gran variedad
de funciones GIS, que son necesarias para periodistas de datos que de vez en 
cuanto tienen que manejar datos geográficos. Si necesita convertir datos geo-espaciales
de un formato a otro, entonces QGis es lo que necesita. Puede manejar casi cualquier
formato de geo-datos que exista (Shapefiles, KML, GeoJSON, etc.). Si necesita
recortar unas cuantas regiones, QGis también puede hacerlo. Además hay una inmensa 
comunidad en torno de QGis, por lo que hay toneladas de recursos http://bit.ly/goettingen-tutorial[como tutoriales]
en la red.

R fue creada principalmente como herramienta de visualización científica. 
Es difícil encontrar un método de visualización o técnica de manejo de datos que
no esté incorporado a R. R es un universo en sí mismo, la meca del análisis visual 
de datos. Una contra es que hay que aprender otro lenguaje de programación, ya 
que R tiene su propio lenguaje. Pero una vez que superó los primeros pasos en 
la curva de aprendizaje, no hay herramienta más poderosa que R. Los periodistas
de datos capacitados pueden usar R para analizar conjuntos de datos inmensos 
que extienden los limites de Excel (por ejemplo, si tiene una tabla con un millón
de filas).

Lo realmente lindo de R es que se puede tener un “protocolo” exacto de lo que está
haciendo con los datos durante todo el proceso, desde la lectura de un archivo CSV 
a generar cuadros. Si los datos cambian puede regenerar el cuadro usando un clic. 
Si alguien tiene curiosidad respecto de la integridad de  su cuadro, puede mostrarle
la fuente exacta, lo que permite a cualquiera recrear el mismo cuadro por su cuenta
(o quizás encontrar los errores que usted cometió).

NumPy + MatPlotLIb es una manera de hacer lo mismo en Python. Es una opción si 
ya está capacitado en Python. De hecho, NumPy y MatPlotLIb son dos ejemplos de
paquetes de Python. Pueden ser usados para análisis y visualización de datos y
los dos se limitan a visualizaciones estáticas. No pueden usarse para crear cuadros
interactivos con consejos sobre el manejo de herramientas y cosas más avanzadas.

Yo no uso MapBox, pero supe que es una gran herramienta si se quiere presentar
mapas más sofisticados basados en OpenStreetMap. Permite por ejemplo adecuar los
estilos del mapa (colores, etiquetas, etc.). También hay un acompañante de MapBox,
llamado Leaflet. Es básicamente una biblioteca de JavaScript de más alto nivel
para mapear que le permite pasar de un proveedor de mapas a otro fácilmente (OSM, 
MapBox, Google Maps, Bing, etc.).

RaphaelJS es una biblioteca de visualización más bien de bajo nivel que le permite
trabajar con elementos primitivos (como círculos, líneas, texto) y animarlos,
agregar interacciones, etc. No contiene nada parecido a un cuadro de barras listo
para usar, por lo que usted mismo tiene que dibujar un conjunto de rectángulos.

Sin embargo, lo bueno de Raphael es que todo lo que crea funciona también en 
Internet Explorer. Eso no sucede con muchas otras bibliotecas de visualización
(asombrosas) como D3. Lamentablemente, tantos usuarios siguen usando IE y ninguna
redacción puede darse le lujo de ignorar al 30% de sus usuarios.

Además de RaphaelJS, también está la opción de crear una alternativa en Flash 
para IE. Es básicamente lo que está haciendo el New York Times. Eso significa 
que tiene que desarrollar cada aplicación dos veces.

Aún no estoy convencido de cuál es el “mejor” proceso para crear visualizaciones
para IE y navegadores modernos. A menudo resulta que las aplicaciones creadas 
con RapahelJS funcionan muy lentas en IE, alrededor de 10 veces más lentas que
con Flash usando navegadores modernos. Por lo que las alternativas en Flash pueden
ser mejor opción si quiere ofrecer visualizaciones animadas de alta calidad para
todos los usuarios.

____

[quote, Steve Doig, Walter Cronkite School of Journalism, Arizona State University]
____
Mi herramienta preferida es Excel, que puede manejar la mayoría de los problemas
CAR (periodismo asistido por computadoras) y tiene las ventajas de ser fácil de
aprender y estar disponible para la mayoría de los periodistas. Cuando necesito
fusionar tablas, comúnmente uso Access, pero luego exporto la tabla fusionada 
de nuevo a Excel para más trabajo. Uso el ArcMap de ESRI para análisis geográficos;
es poderoso y es utilizado por las agencias que recopilan datos geo-codificados.
TextWrangler es muy bueno para examinar datos de texto con diseños y delimitadores
complicados, y puede hacer búsqueda y reemplazo sofisticada con expresiones 
regulares. Cuando se necesita técnicas estadística, como regresión lineal, uso SPSS;
tiene un menú para señalar y cliquear fácil de usar. Para trabajos realmente
pesados, como las tareas con conjuntos de datos que tienen millones de registros 
que necesitan un importante filtrado y transformaciones de variables programadas,
uso software SAS.
____

[quote, Brian Boyer, Chicago Tribune]
____
Entre nuestras herramientas preferidas se incluyen Python y Django para hackear,
scrapear y jugar con datos; y PostGIS, QGIS y las herramientas de MapBow para
crear mapas locos en la red. R y MumPy + MatPlotLib actualmente disputan la 
supremacía como nuestro equipo de trabajo para análisis de datos exploratorio,
aunque últimamente nuestra herramienta de datos preferida es de nuestra propia
cosecha: CSVKit. Hacemos casi todo en la nube. 
____

[quote, Angélica Peralta Ramos, La Nacion (Argentina)]
____

En La Nación usamos:

*	Excel para limpiar, organizar y analizar datos,
*	Google Spreadsheets para edición y conexión con servicios tales como Google
Fusion Tables y la Junar Open Data Platform,
*	Junar para compartir nuestros datos e incrustarlos en nuestros artículos y
actualizaciones del blog,
*	Tableau Public para nuestras visualizaciones de datos interactivas,
*	Qlikview, una herramienta de inteligencia para empresas muy rápida para 
analizar y filtrar conjuntos de datos grandes,
*	NitroPDF para convertir PDF a archivos de texto y Excel,
*	Google Fusion Tables para visualizaciones de mapas.

____

[quote, Pedro Markun, Transparência Hacker]
____

Como comunidad de base sin preferencias técnicas, en Transparency Hackers usamos
muchas herramientas y lenguajes de programación diferentes. Cada miembro tiene
su propio conjunto de preferencias y esta gran variedad es al mismo tiempo nuestro
punto fuerte y nuestra debilidad. Algunos estamos construyendo una “Versión de
Linux para Hackers de Transparencia”, que podamos iniciar en cualquier parte para
hackear datos. Este recurso tiene algunas herramientas y bibliotecas interesantes
para manejar datos como Refine, RStudio y OpenOffice Calc (por lo general una herramienta
poco usada por la gente que conoce del tema, pero realmente útil para cosas
rápidas/pequeñas). También hemos estado usando ScraperWiki mucho para hacer prototipos 
rápidamente y guardar resultados de datos online.

Hay muchas herramientas que nos gustan para visualizaciones de datos y gráficos. 
Python y NumPy son bastante poderosas. Alguna gente de la comunidad ha estado 
jugando con R, pero en definitiva las bibliotecas para ploteado de gráficos, 
como D3, Flot, y RaphaelJS es lo que se termina usando en la mayoría de nuestros
proyectos. Finalmente, hemos estado experimentando mucho con mapeado, y Tilemill
ha sido una herramienta muy interesante para este trabajo.
____

=== Usar visualizaciones para descubrir cosas en los datos 

[quote, William S. Cleveland (de Visualizing Data, Hobart Press)]
____
La visualización es crítica para el análisis de datos. Aporta una primera línea
de ataque, revelando estructuras intrincadas en datos que no pueden ser absorbidas
de otro modo. Descubrimos efectos inimaginados y cuestionamos aquellos que han
sido imaginados.
____

Los datos por sí mismos, que consisten de bits y bytes almacenados en un archivo
en el disco rígido de una computadora, son invisibles. Para poder verlos y encontrarles
sentido, necesitamos visualizarlos. En esta sección voy a usar el término visualizar
en un sentido más amplio, que incluye incluso representaciones textuales puras
de datos. Por ejemplo, simplemente cargar un conjunto de datos en un software 
de planilla de cálculo puede considerarse una visualización de datos. Los datos
invisibles de pronto se convierten en una “imagen” visible en nuestra pantalla.
Por tanto, la pregunta no debe ser si los periodistas necesitan visualizar los
datos o no, sino qué tipo de visualización puede ser la más útil en cada situación.

Dicho de otro modo: ¿cuándo tiene sentido ir más allá de la visualización en tablas? 
La respuesta más simple es: casi siempre. Las tablas por sí solas decididamente 
no bastan para darnos una visión general de un conjunto de datos. Y las tablas
por sí solas no nos permiten identificar inmediatamente patrones dentro de los
datos. El ejemplo más común aquí son los patrones geográficos que solo pueden 
observarse al visualizar datos en un mapa. Pero también hay otros tipos de patrones,
que veremos luego en esta sección.

==== Usar visualización de datos para descubrir información clarificadora

No es realista esperar que herramientas y técnicas de visualización de datos 
disparen una andanada de historias listas para usar a partir de los conjuntos
de datos. No hay reglas ni “protocolos” que nos garanticen que tendremos una 
historia. En cambio, creo que tiene más sentido buscar “percepciones”, que un 
buen periodista puede incorporar a historias.

Cada nueva visualización puede darnos percepciones sobre nuestros datos. Parte
de esa información reveladora puede ser conocida ya (pero quizás aún no demostrada),
mientras que otros aspectos pueden resultarnos completamente nuevos o incluso
sorprendentes. Algunas cosas nuevas que percibimos podrían significar el comienzo
de una historia, mientras que otras podrían ser simplemente el resultado de errores
en los datos, que es más probable que encontremos visualizando los datos.

Para hacer más efectiva la búsqueda de nuevas percepciones en los datos, me resulta
de gran ayuda el proceso representado en <<FIG054>> (y descripto en el resto
de esta sección).

[[FIG054]]
.Información reveladora en datos; una visualización (Gregor Aisch)
image::figs/incoming/05-BB.png[float="none"]

===== Aprenda a visualizar datos

La visualización ofrece una perspectiva particular sobre el conjunto de datos.
Usted puede visualizar datos de muchas maneras diferentes.

Las tablas son muy poderosas cuando se trata de un número relativamente pequeño
de puntos. Muestran etiquetas y montos del modo más estructurado y organizado
y revelan su potencial plenamente cuando se las combina con la capacidad de 
ordenar y filtrar los datos. Adicionalmente, Edward Tufte sugirió incluir pequeños 
gráficos dentro de columnas de tablas, por ejemplo, una barra por fila o una 
pequeña línea de cuadro (desde entonces conocida también como sparkline). Pero
aún así, y tal como ya dijimos, las tablas claramente tienen limitaciones. Son
muy buenas para mostrar cuestiones unidimensionales, como los primeros 10, pero
son muy pobres cuando se trata de comparar múltiples dimensiones simultáneamente
(por ejemplo, población por país a lo largo del tiempo).

[[FIG055]]
.Consejos de Tufte: sparklines (Gregor Aisch)
image::figs/incoming/05-BC-graphical-table.png[float="none"]

Los cuadros, en general, le permiten vincular dimensiones de sus datos con 
propiedades visuales de formas geométricas. Mucho se ha escrito sobre la efectividad
de las propiedades visuales individuales, y la versión más breve de todo ello es:
el color es difícil, la posición es todo. En un diagrama de dispersión, por ejemplo,
se relaciona dos dimensiones con las posiciones x- e y-. Incluso se puede presentar
una tercera dimensión relacionada con el color o el tamaño de los símbolos presentados.
Los cuadros lineales son especialmente adecuados para mostrar evoluciones temporales,
mientras que los cuadros de barras son perfectos para comparar datos de categorías.
Se puede apilar elementos de cuadros. Si desea comparar un pequeño número de grupos
de sus datos, presentar múltiples instancias del mismo gráfico es una forma 
muy poderosa de hacerlo (también conocido como múltiplos pequeños). En todos 
los cuadros se puede usar distintos tipos de escalas para explorar aspectos 
diferentes de los datos (por ejemplo, lineal o escala logarítmica).

De hecho la mayor parte de los datos que manejamos están relacionados de algún
modo con gente real. El poder de los mapas es que reconectan los datos con nuestro
mundo físico. Imagine un conjunto de datos de incidentes criminales ubicados 
geográficamente. Lo crucial es ver dónde suceden los crímenes. Además los mapas
pueden revelar relaciones geográficas dentro de los datos (por ejemplo, una tendencia 
de norte a sur, o de zonas urbanas a rurales).

[[FIG056]]
.Mapa coroplético (Gregor Aisch)
image::figs/incoming/05-BD-choropleth.png[float="none"]

Hablando de relaciones, el cuarto tipo más importante de visualización es el 
gráfico. Los gráficos sirven para mostrar las interconexiones (bordes) de sus 
puntos de datos (nodos). La posición de los nodos se calcula entonces por algoritmos 
de diagrama de gráficos más o menos complejos que nos permiten ver inmediatamente
la estructura dentro de la red. El truco de la visualización por gráficos en 
general es encontrar el modo adecuado para modelar la red misma. No todos los
conjuntos de datos incluyen ya relaciones y aunque las incluyan puede no ser 
el aspecto más interesante. A veces el periodista tiene que definir los bordes
entre nodos. Un ejemplo perfecto de esto es el http://slate.me/senate-social[Gráfico Social del Senado]
de EE.UU., cuyos bordes conectan senadores que votaron lo mismo en más del 65%
de los casos.

===== Analice e intérprete lo que ve

Una vez que haya visualizado sus datos, el siguiente paso es aprender algo del
cuadro que creó. Podría preguntarse:

	* ¿Qué puedo ver en esta imagen? ¿Es lo que esperaba?
	* ¿Hay patrones interesantes?
	* ¿Qué significa esto en el contexto de los datos?

A veces puede terminar con una visualización que, pese a su belleza, puede no
decirle nada de interés de sus datos. Pero casi siempre hay algo que puede 
aprender de cualquier visualización, por trivial que sea.

===== Documente sus percepciones y sus pasos

Si piensa en este proceso como un viaje a través del conjunto de datos, la 
documentación es su diario de viaje. Dirá a dónde viajó, que ha visto allí y 
cómo tomó sus decisiones para sus siguientes pasos. Incluso puede comenzar 
con su documentación antes de echar su primera mirada a los datos.

En la mayoría de los casos cuando comenzamos a trabajar con un conjunto de datos 
que no hemos visto previamente, ya estamos llenos de expectativas y supuestos 
sobre los datos. Por lo general hay un motivo por el que estamos interesados 
en el conjunto de datos que estamos mirando. Es buena idea comenzar la 
documentación escribiendo estos pensamientos iniciales. Esto nos ayuda a identificar 
nuestros prejuicios y reduce el riesgo de malas interpretaciones de los datos 
encontrando simplemente lo que queríamos encontrar originalmente.

Realmente creo que la documentación es el paso más importante del proceso, y 
es también el que somos más proclives a dejar de lado. Como verá en el ejemplo 
que viene a continuación, el proceso descripto involucra mucha planificación 
y manejo de datos. Mirar un conjunto de 15 cuadros que ha creado puede ser muy 
confuso, especialmente al transcurrir algún tiempo. De hecho esos cuadros solo 
son valiosos (para usted o cualquier persona a la que quiera comunicar lo que 
descubrió) si se los presenta en el contexto en el que fueron creados. Por tanto 
debe tomarse algún tiempo para hacer notas sobre cosas como:

	* ¿Por qué creé este cuadro?
	* ¿Qué he hecho con los datos para crearlo?
	* ¿Qué me dice este cuadro?

===== Transforme los datos

Naturalmente con las nuevas cosas que percibió con la última visualización, 
puede tener una idea de lo que quiere ver a continuación. Puede haber encontrado 
algún patrón interesante en el conjunto de datos que ahora quiere inspeccionar 
con más detalle.

Las posibles transformaciones:

Acercamiento (zoom)::
Para ver cierto detalle en la visualización
Agregación::
Combinar muchos puntos de datos en un solo grupo.
Filtrado::
Eliminar (temporariamente) puntos de datos que no son de nuestro mayor interés
Eliminación de datos atípicos::
Eliminar puntos individuales que no son representativos del 99% del conjunto 
de datos.

Situémonos en el caso de que usted ha visualizado un gráfico y lo que surgió 
no fue más que un enredo de nodos conectados por cientos de bordes (un resultado 
muy común cuando se visualiza lo que se llama redes densamente conectadas). 
Un paso de transformación común sería filtrar algunos bordes. Si, por ejemplo, 
los bordes representan flujos de dinero de países donantes a países receptores, 
podríamos eliminar todos los flujos menores a cierto monto.

==== Qué herramientas usar

La cuestión de las herramientas no es fácil. Toda herramienta de visualización 
de datos disponible es buena para algo. La visualización y el manejo de los 
datos debe ser fácil y barato. Si cambiar los parámetros de las visualizaciones 
le lleva horas, no va a experimentar demasiado. Eso no quiere decir necesariamente 
que no deba aprender cómo usar la herramienta. Pero una vez que aprendió, debiera 
ser realmente eficiente.

A menudo hay que tener mucho criterio para elegir una herramienta que cubra 
tanto las cuestiones del manejo de los datos como la visualización de datos. 
Separar las tareas en distintas herramientas significa que tiene que importar 
y exportar datos muy a menudo. Esta es una breve lista de algunas herramientas 
de visualización y manejo de datos:

	* Planillas de cálculo como LibreOffice, Excel o Google Docs
	* Plataformas de programación estadística como R (r-project.org) o Pandas
(pandas-pydata.org)
	* Sistemas de Información Geográfica (GIS) como Quantum GIS, ARcGIS, 
o GRASS
	* Biblitoecas de Visualización como d3.js (mbostock.github.com/d3), 
Prefuse (prefuse.org) o Flare (flare.prefuse.org)
	* Herramientas de manejo de datos como Google Refine o Datawrangler
	* Software para crear visualizaciones como ManyEyes o Tableau Public 
(tableausoftware.com/products/public)

Las visualizaciones de muestra en la siguiente sección fueron creadas usando 
R, que es el cortaplumas suizo de la visualización de datos (científica).

==== Un ejemplo: encontrarle sentido a los datos sobre contribuciones electorales

Veamos la base de datos de las Finanzas de la Campaña Presidencial de Estados
Unidos, que contiene alrededor de 450.000 aportes a candidatos presidenciales
estadounidenses. El archivo CSV es de 60 megabytes y demasiado grande para manejar
fácilmente en un programa como Excel.

En el primer paso escribiré explícitamente mis supuestos iniciales respecto 
del conjunto de datos sobre contribuciones para las campañas electorales:

	* Obama recibe la mayor suma en contribuciones (dado que es el presidente
y tiene la mayor popularidad)
	* La cantidad de contribuciones aumenta al acercarse la fecha de las 
elecciones.
	* Obama recibe más contribuciones pequeñas que los candidatos republicanos
	
Para responder a la primera pregunta, tenemos que transformar los datos. En vez de 
cada contribución individual, necesitamos sumar el total de lo aportado a cada 
candidato. Luego de visualizar los resultados en una tabla ordenada, confirmamos 
nuestro supuesto de que Obama obtendría la mayor cantidad de dinero:

[options="header"]
|=======================
|Candidato | Monto ($)
|Obama, Barack | 72.453.620,39
|Romney, Mitt | 50.372.334,87
|Perry, Rick | 18.529.490,47
|Paul, Ron | 11.844.361,96
|Cain, Herman | 7.010.445,99
|Gingrich, Newt | 6.311.193,03
|Pawlenty, Timothy | 4.202.769,03
|Huntsman, Jon | 2.955.726,98
|Bachmann, Michelle | 2.607.916,06
|Santorum, Rick | 1.413.552,45
|Johnson, Gary Earl | 413.276,89
|Roemer, Charles E. 'Buddy' III | 291.218,80
|McCotter, Thaddeus G | 37.030,00
|=======================

Si bien esta tabla muestra los montos mínimo y máximo y el orden, no dice 
demasiado acerca de los patrones subyacentes al ranking de los candidatos. 
<<FIG059>> es otra vista de los datos, un tipo de cuadro conocido como “cuadro 
de puntos”, en el que podemos ver todo lo que aparece en la tabla más los 
patrones dentro del campo. Por ejemplo, el cuadro de puntos nos permite 
comparar inmediatamente la distancia entre Obama y Romney y Romney y Perry, 
sin tener que restar valores. (Nota: este cuadro de puntos fue creado usando 
R. Puede encontrar vínculos con el código fuente al final de este capítulo).

[[FIG059]]
.Visualizaciones para descubrir patrones subyacentes (Gregor Aisch)
image::figs/incoming/05-CC.png[float="0"]

Ahora procedamos con un cuadro más grande del conjunto de datos. Como primer 
paso, visualicé todos los montos aportados a lo largo del tiempo en una sola 
vista. Podemos ver que casi todas las contribuciones son muy, muy pequeñas 
comparado con 3 casos salientes. Una investigación más a fondo revela que estas 
contribuciones inmensas provienen del “Fondo para la Victoria de Obama 2012” 
(también conocido como SuperPAC) y se hicieron el 9 de junio (US$ 450.000), 
septiembre 29 (US$ 1.500.000) y diciembre 30 (US$ 1,900.000).

[[FIG0510]]
.3 casos salientes (Gregor Aisch)
image::figs/incoming/05-DD.png[float="none"]

Si bien las contribuciones de Súper PACs por si solas son sin duda la historia 
más importante en los datos, podría ser interesante mirar más allá. La cuestión 
ahora es que estas grandes contribuciones perturban nuestra visión de las 
contribuciones más pequeñas que provienen de individuos, por lo que vamos a 
quitarlas de los datos. Esta transformación se conoce comúnmente como eliminación
de datos atípicos. Luego de visualizar nuevamente, podemos ver que la mayoría 
de las donaciones están dentro del rango de entre US$ 5.000 y US$ 10.000.

[[FIG0511]]
.Eliminar datos atípicos (Gregor Aisch)
image::figs/incoming/05-EE.png[float="none"]


De acuerdo al límite a las contribuciones establecidos por FECA (autoridad 
electoral), no se permite a los individuos donar más de US$ 2500 a cada 
candidato. Como podemos ver en el gráfico, hay numerosas donaciones por encima
de ese límite. En particular, nos llaman la atención dos grandes contribuciones 
en mayo. Parece que son compensadas por montos negativos (reembolsos) en junio 
y julio. Una investigación más a fondo de los datos revela las siguientes 
transacciones:

	* El 10 de mayo, _Stephen James Davis_, de San Francisco, empleado en Banneker
Partners (abogados), ha donado *US$ 25.800* a Obama.
	* El 25 de mayo, _Cynthia Murphy_, de Little Rock, empleada en el Murphy Group
(relaciones públicas), ha donado *US$ 33.300* a Obama 
	* El 15 de junio el monto de *US$ 30.800* fue devuelto a _Cynthia Murphy_, 
lo que redujo el monto donado a US$ 2500.
	* El 8 de julio, se devolvió el monto de *US$ 25.800* a _Stephen James Davis_, 
lo que redujo el monto donado a US$ 0.

¿Qué tienen de interesantes estas cifras? Los US$ 30.800 devueltos a Cynthia 
Murphy equivalen al monto máximo que pueden dar individuos a comités nacionales 
de partidos al año. Quizás quería combinar ambas donaciones en una transacción, 
que fue rechazada. Los US$ 25.800 devueltos a Stephen James Davis posiblemente 
equivalen a los US$ 30.800 menos US$ 5000 (el límite de aportes a cualquier otro 
comité político).

Otra cosa interesante descubierta en el último gráfico es un patrón lineal 
horizontal de contribuciones para candidatos republicanos por US$ 5000 y -US$ 2500.
Para verlos con más detalle, visualicé solo las donaciones a republicanos. El 
gráfico resultante es un gran ejemplo de patrones en datos que serían invisibles 
sin visualización de datos.

[[FIG0512]]
.Eliminación de datos atípicos 2 (Gregor Aisch)
image::figs/incoming/05-FF.png[float="none"]

Lo que podemos ver es que hay muchas donaciones de US$ 5000 a candidatos 
republicanos. De hecho, un análisis de los datos da que hay 1243 de estas 
donaciones, que es solo el 0,3% del número total de donaciones, pero debido 
a que esas donaciones se reparten de modo parejo en el tiempo, la línea 
aparece. Lo interesante de la línea es que las donaciones de individuos 
estaban limitadas a US$ 2500. En consecuencia cada dólar que superó ese 
límite fue devuelto a los donantes, lo que resulta en la segunda línea de 
–US$ 2500. En contraste, las contribuciones a Barack Obama no muestran un 
patrón similar.

[[FIG0513]]
.Eliminación de datos atípicos 3 (Gregor Aisch)
image::figs/incoming/05-GG.png[scale="86",float="none"]

Por lo que podría ser interesante averiguar por qué miles de donantes 
republicanos no advirtieron los límites para donaciones de individuos. Para 
analizar más en profundidad el tema, podemos ver el número total de donaciones 
de US$ 5000 por candidato.

[[FIG0514]]
.Donaciones por candidato (Gregor Aisch)
image::figs/incoming/05-HH.png[scale="86",float="none"]

Por supuesto que esta es una visión distorsionada dado que no considera los 
montos totales de donaciones recibidas por cada candidato. El siguiente gráfico
muestra el porcentaje de donaciones de US$ 5000 por candidato.

[[FIG0515]]
.¿De dónde viene la plata del senador?: donaciones por candidato (Gregor Aisch)
image::figs/incoming/05-II.png[scale="88",float="none"]

==== Qué aprender de esto

A menudo tal análisis visual de un nuevo conjunto de datos se vive como un 
viaje excitante a un país desconocido. Uno comienza como un extranjero contando
solo con los datos y sus supuestos, pero con cada paso que da, con cada cuadro
que produce, percibe cosas nuevas sobre el tópico. Basado en esas percepciones,
toma decisiones respecto de sus siguientes pasos y que cuestiones ameritan 
una mayor investigación. Como habrá visto en este capítulo, este proceso de 
visualizar, analizar y transformar datos podría repetirse casi al infinito.

==== Consiga el código fuente

Todos los cuadros que se muestran en este capítulo fueron creados usando el 
maravilloso y poderoso software R. Creado principalmente como herramienta de 
visualización científica, es difícil encontrar alguna técnica de visualización 
o manejo de datos que no esté incorporada a R. Para aquellos interesados en 
saber cómo visualizar y manejar datos usando R, a continuación aparecen los 
códigos fuente para los cuadros generados en este capítulo:

	* https://gist.github.com/1769733[Cuadro de puntos: contribuciones por candidato] 
	* https://gist.github.com/1816161[Gráfico: todas las contribuciones a lo largo del tiempo] 
	* https://gist.github.com/1816169[Gráfico: contribuciones por comités autorizados] 

Hay también una gran variedad de libros y tutoriales disponibles.

&mdash; _Gregor Aisch, Open Knowledge Foundation_


