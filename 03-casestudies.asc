:chapnum: 03
:figure-number: 00

== Estudio de casos

image::figs/incoming/03-00-cover.png[float="none",role="informal"]

En esta sección analizamos con más profundidad el detrás de escena de
numerosos proyectos de periodismo de datos, desde aplicaciones
desarrolladas en un día, hasta investigaciones de 9 meses de duración.
Nos informamos sobre cómo han sido usadas fuentes de datos para aumentar
y mejorar la cobertura de diferentes temas, desde elecciones hasta
gasto, de disturbios hasta corrupción, desde el nivel educativo de las
escuelas hasta el precio del agua. Junto a organizaciones de grandes
medios, tales como la BBC, el Chicago Tribune, The Guardian, el
Financial Times, Helsingin Sanomar, La Nación, el Wall Street Journal, y
el Zeit Online, también presentamos iniciativas más pequeñas tales como
las de California Watch, Hack/HackersBeunos Aires, ProPublica y un grupo
de ciudadanos-periodistas brasileños llamados amigos de Januária.

=== La brecha de oportunidades

http://projects.propublica.org/schools[The Opportunity Gap] (La Brecha de Oportunidades,
usó datos de derechos civiles nunca antes difundidos del departamento de
Educación de Estados Unidos y mostró que algunos estados, como Florida,
han creado una situación equitativa ofreciendo a estudiantes ricos y
pobres un acceso equitativo en términos generales a cursos de alto
nivel, mientras que otros estados, como Kansas, Maryland y Oklahoma,
ofrecen menos oportunidades en distritos con familias más pobres.

[[FIG031]]
.The Opportunity Gap project (ProPublica)
image::figs/incoming/03-YY.png[float="none"]

Los datos incluyen a las escuelas públicas de todo distrito con 3000
estudiantes o más. Estan representados más de 3 cuartos de todos los
alumnos de escuelas públicas. Un reportero de nuestra redacción obtuvo
los datos y nuestro Director de Informes Asistidos por Computadora los
depuró en profundidad.

Fue un proyecto que llevó aproximadamente 3 meses. En total 6 personas
trabajaron en la historia y la aplicación de noticias: 2 editores, un
redactor, una persona de Informes asistidos por computadora y 2
programadores. La mayoría no trabajó exclusivamente en este proyecto
durante ese período.

El proyecto requirió realmente nuestras capacidades combinadas: profundo
conocimiento del tema, una comprensión de las mejores prácticas con
datos, capacidades de diseño y programación. Lo que es más importante,
requirió la capacidad de encontrar la historia en los datos. También
exigió edición, no solo para la historia que la acompaña, sino también
para la aplicación de noticias.

Para la depuración y análisis de los datos usamos principalmente Excel y
rutinas de depuración, así como MS Access. La aplicación
de noticias fue desarrollada con el programa Ruby on Rails y usa
abundantemente JavaScript.

Además de un artículo que da el marco general, nuestra cobertura incluyó
una aplicación de noticias interactiva que permite a los lectores
comprender y encontrar ejemplos que se relacionen con su propia
situación dentro de esta gran base de datos nacional. Utilizando nuestra
aplicación de noticias, el lector podía encontrar su escuela local
–digamos, por ejemplo, http://goo.gl/HJVCf[Central High School en Newark, N.J.]_
y ver inmediatamente el
desempeño relativo de la escuela en una gran variedad de áreas. Entonces
podía cliquear un botón que dice http://goo.gl/WrAIi[“comparar con Escuelas de Alta y Baja
Pobreza”], e inmediatamente
ver otras escuelas medias y su pobreza relativa, y la medida en la que
ofrecen matemática avanzada, Advanced Placement (conocido con la sigla
AP, un programa de la dirección de Colleges, que ofrece currícula y
exámenes de nivel de College para estudiantes de secundaria en Estados
Unidos, n. del t.) y otros cursos importantes. En nuestro ejemplo,
Central High tiene como referencia a Millburn Sr. High. La Brecha de
Oportunidades muestra que sólo el 1% de los estudiantes de Milburn
recibe almuerzo gratis o a precio reducido y el 72% de ellos hace al
menos un curso de AP. En el otro extremo, en el International High el
85% de sus estudiantes recibe almuerzo gratis o a precios reducidos y
solo 1% toma cursos AP.

A través de este ejemplo el lector puede usar información que conoce –de
una escuela media local- para averiguar algo que no sabe: la
distribución de la accesibilidad educativa y en qué medida la pobreza
predice esa accesibilidad.

También integramos la aplicación con Facebook, de modo que los lectores
pudieran loguearse esta a esta red social y nuestra aplicación
automáticamente les haría saber de escuelas que podrían interesarles.

El tráfico hacia todas nuestras aplicaciones de noticias es excelente y
estamos particularmente orgullosos del modo en que ella cuenta una
historia compleja; y, lo que va más al grano, ayuda a los lectores a
definir su propia historia.

Tal como sucede con muchos proyectos que parten de información oficial,
los datos requirieron mucha depuración. Por ejemplo, si bien sólo hay
alrededor de 30 posibles cursos de Advanced Placement, algunas escuelas
informaban que tenían cientos de ellos. Esto exigió muchos chequeos
manuales y llamadas telefónicas a escuelas para confirmaciones y
correcciones.

También trabajamos fuerte para asegurarnos que la aplicación ofreciera
una versión “lejana” y una versión “cercana” de la historia. Es decir,
la aplicación tenía que presentar al lector un cuadro nacional amplio y
abstracto; una manera de comparar a los estados en materia de acceso
educativo. Pero dado que la abstracción a veces genera confusión en los
lectores respecto de lo que los datos significan para ellos, también
queríamos que los lectores pudieran encontrar sus escuelas locales y
compararlas con escuelas de baja pobreza en su área.

Si quisiera aconsejar a quienes quieren ser periodistas de datos y
abordar proyectos de este tipo, diría que tienen que conocer el material
y ser inquisitivos. Todas las reglas que valen para otros tipos de
periodismo, valen también aquí. Hay que tener datos ciertos, asegurarse
de contar bien la historia y -cuestión crucial- asegurarse de que su
aplicación de noticias no contradiga la historia que está escribiendo.
Si lo hace, una de las 2 podría estar equivocada.

Además, si usted quiere aprender a programar, lo más importante es
empezar. Usted puede preferir aprender a través de clases, libros o
videos, pero asegúrese de tener una idea realmente buena para un
proyecto y un plazo para completarlo. Si tiene una historia en la cabeza
que solo puede expresarse a través de una aplicación de noticias,
entonces no saber programar no lo va a detener.

&mdash; _Scott Klein, ProPublica_

=== Una investigación de 9 meses sobre Fondos Estructurales Europeos

En 2010, el http://www.ft.com/intl/eu-funds[Financial Times]
y el http://bit.ly/bureau-billions[Bureau of Investigative Journalism (BIJ)] 
se unieron para investigar los Fondos Estructurales Europeos. La
intención era revisar quiénes son los beneficiarios de esos fondos y
verificar si el dinero se usó para bien. Con € 347.000 millones a lo
largo de 7 años, los Fondos Estructurales son el segundo programa de
subsidios de la Unión Europea. El programa existe desde hace décadas,
pero fuera de informes generales, había poca transparencia respecto de
quiénes eran los beneficiarios. Como parte de un cambio de reglas en la
actual ronda de otorgamiento de fondos, las autoridades están obligadas
a hacer pública una lista de beneficiarios, incluyendo la descripción de
los proyectos y el monto de fondos de la UE y nacionales recibidos.

[[FIG032]]
.Investigación de Fondos Estructurales de la UE (Financial Times y el Bureau of Investigative Journalism)
image::figs/incoming/03-OO-01.png[float="none"]

El equipo del proyecto estaba compuesto por 12 periodistas y un
programador tiempo completo colaborando por 9 meses. La recolección de
los datos por sí sola llevó varios meses.

El proyecto se publicó en 5 días de cobertura en el Financial Times y el
BIJ, un documental radial de la BBC y varios documentales de TV.

Antes de abordar un proyecto con este nivel de esfuerzo hay que estar
seguro de que lo descubierto es original y que se terminará teniendo
buenas historias que nadie más tiene.

El proceso se dividió en una serie de pasos diferentes.

==== 1. Identificar quién registra los datos y cómo

El Directorio General de las Regiones de la Comisión Europea tiene un http://bit.ly/ec-portal[portal] de los sitios
de autoridades regionales que publican los datos. Creíamos que la
Comisión tendría una base de datos general de proyectos a la que
podríamos acceder directamente o que podríamos obtener a través de un
pedido de acceso a la información. No existe tal base de datos con el
nivel de definición requerido. Rápidamente advertimos que muchos de los
vínculos provistos por la comisión eran erróneas y que la mayoría de las
autoridades publicaban los datos en formato PDF, en vez de formatos que
faciliten el análisis tales como CSV o XML.

Un equipo de 12 personas trabajó para identificar los datos más
actualizadas y ordenar los vínculos reuniéndolos en una planilla de
cálculo que usamos para colaboración. Dado que los campos de datos no
eran uniformes (por ejemplo, los encabezados estaban en distintos
idiomas, algunos conjuntos de datos usaban diferentes divisas, y algunos
incluían descomposición en fondos de UE y nacionales) tuvimos que ser lo
más precisos posible en la traducción y [line-through]*la*descripción de
los campos de datos disponibles en cada conjunto.

==== 2. Descargar y preparar los datos

El siguiente paso consistió en descargar todas las planillas de cálculo,
PDF y, en algunos casos, recopilar datos originales en la red.

Cada conjunto de datos tuvo que ser estandarizado. Nuestra mayor tarea
fue extraer datos de cientos de páginas en formato .PDF. Gran parte de
esto se hizo utilizando UnPDF y ABBYY FineReader, que permiten extraer
datos a formatos tales como CSV o Excel.

También significó verificar y volver a verificar que las herramientas de
extracción de PDF hubiesen captado los datos correctamente. Esto se hizo
filtrando, ordenando y sumando totales (para asegurarnos que se
correspondieran con lo publicado en los PDF).

==== 3. Crear una base de datos

El programador del equipo creó una base de datos SQL. Cada uno de los
archivos preparados fue utilizado entonces como unidad para la
construcción de la base de datos SQL general. Con un proceso diario se
cargaba todos los archivos individuales de datos en una gran base de
datos SQL, en la que se podían realizar búsquedas en cualquier momento a
través de su interfaz con palabras claves.

==== 4. Doble verificación y análisis

El equipo analizó los datos de 2 maneras principales:

Vía la interfaz de la base de datos::

Esto significó tipear palabras claves de interés (por ejemplo, “tabaco”,
“hotel”, “compañía A” en el motor de búsquedas. Con la ayuda de Google
Translate, que fue incorporado a la funcionalidad de búsquedas de
nuestra base de datos, esas palabras claves se traducían a 21 idiomas,
obteniendo los resultados apropiados. Estos se podían descargar y los
periodistas podían continuar su investigación en proyectos individuales
de su interés.

Por macro-análisis usando toda la base de datos::

Ocasionalmente descargábamos un conjunto de datos completo, que entonces
podía ser analizado (por ejemplo, usando palabras clave o agregando
datos por país, región, tipo de gasto, número de proyectos por
beneficiarios, etc.)

Nuestras historias se conformaron con ambos métodos, pero también a
través de investigación de campo y de escritorio.

Hacer la doble verificación de la integridad de los datos (agregando y
verificando en comparación con lo que las autoridades dijeron que fue
asignado) llevó una gran cantidad de tiempo. Uno de los principales
problemas fue que las autoridades mayormente solo divulgaban la cantidad
de “fondos de la UE y nacionales”. Bajo las reglas de la UE, cada
programa puede cubrir un porcentaje del costo total usando fondos de la
UE. El nivel de financiación por la UE es determinado, al nivel del
programa, por la llamada tasa de co-financiación. Cada programa (por
ejemplo, competitividad regional) está compuesto de numerosos proyectos.
Al nivel de los proyectos, técnicamente, uno podría recibir ciento por
ciento de financiación de la UE y otro nada, mientras el monto total de
la financiación por la UE al nivel de los programas no superara la tasa
de co-financiación aprobada.

Esto significó que tuvimos que verificar con cada compañía beneficiaria
el monto de financiación de la UE que citamos en nuestras historias.

&mdash; _Cynthia O'Murchu, Financial Times_

=== El colapso de la Eurozona

Estamos http://on.wsj.com/tYM82O[cubriendo el colapso de la Eurozona]. 
Todos los aspectos. El dramatismo de los enfrentamientos entre gobiernos y la
pérdida de los ahorros de toda la vida; la reacción de los líderes
mundiales, las medidas de austeridad, y las protestas en contra de estas
medidas. Todos los días en el Wall Street Journal hay cuadros sobre
pérdidas de empleos, caída de PBI y hundimiento de los mercados
mundiales. Es incremental. Y aturde.

Los editores de tapa convocan una reunión para debatir ideas sobre la
cobertura de fin de año y en momentos en que me voy de la reunión, me
pregunto: ¿Cómo será vivir esto?

¿Es esto como 2008 cuando me echaron y las malas noticias eran
incesantes? Hablábamos de empleo y dinero todas las noche en la cena,
casi sin pensar en cómo podía intranquilizar a mi hija. Y los fines de
semana eran lo peor. Yo trataba de negar el temor que parecía dominarme
permanentemente y la ansiedad que no me dejaba respirar. ¿Así vive una
familia ahora mismo en Grecia? ¿En España?

Me volví y seguí a Mike Allen, el editor de tapa, a su oficina le
propuse la idea de contar la crisis a través de familias en la Eurozona
mirando primero los datos, encontrando perfiles demográficos para
entender la composición familiar y luego sacando eso a luz junto con las
imágenes y entrevistas, audio de las distintas generaciones. Usaríamos
hermosos elementos de retrato, las voces … y los datos.

Cuando volví a mi escritorio escribí un resumen y dibujé un logo.

[[FIG033]]
.El colapso de la Eurozona: resumen (Wall Street Journal)
image::figs/incoming/03-ZZ-01.png[float="none"]

Durante las siguientes 3 semanas perseguí cifras: métricas sobre
matrimonio, mortalidad, el tamaño de las familias y gasto en salud. Leí
sobre condiciones de vida y tasas de divorcio, miré encuestas sobre
bienestar y tasas de ahorro. Estudié estadísticas nacionales, llamé al
bureau de población de la ONU, el FMI, Eurostat, y la OCDE hasta que
encontré un economista que había pasado su carrera siguiendo familias.
Me conectó con una estudiosa sobre composición familiar. Me indicó
trabajos sobre mi tema.

Con mi editor, Sam Enriquez, redujimos el número de países. Reunimos un
equipo para debatir el enfoque visual y qué periodistas producirían
palabras, audio y la historia. Matt Craig, el editor fotográfico de
tapa, se puso a trabajar para encontrar fotógrafos. Matt Murray, el
subeditor ejecutivo para cobertura mundial, envió un memo a los jefes de
sección pidiendo ayuda de los periodistas. (Esto fue crucial: la orden
de la máxima jerarquía).

Pero primero los datos. Por la mañana yo exportaba datos a planillas de
cálculo y hacía cuadros para ver tendencias: caída del ahorro,
desaparición de pensiones, la vuelta de madres al trabajo, gasto en
salud, junto con deuda pública y desempleo. Por la tarde analizaba esos
datos agrupados, comparando los países para encontrar historias.

Lo hice durante una semana antes de enredarme en los yuyos y comenzar a
dudar de mi misma. Quizás fuera un enfoque equivocado. Quizás no debía
tratarse de países, sino de padres y madres, y niños y abuelos. Los
datos aumentaron.

Y se redujeron. A veces pasaba horas reuniendo información que en
definitiva no me decía nada. Había buscado un conjunto de cifras
equivocado. En algunos casos los datos eran simplemente demasiado
viejos.

[[FIG034]]
.Juzgar la utilidad de un conjunto de datos puede ser una tarea que lleve mucho tiempo Sarah Slobin)
image::figs/incoming/03-ZZ-04.png[float="none"]

Luego los datos volvieron a aumentar al advertir que aún tenía
interrogantes y no entendía las familias.

Necesitaba verlo, moldearlo. Por lo que hice una serie rápida de
gráficos en Illustrator y comencé a ordenarlos y editarlos.

Al emerger los cuadros, también apareció una imagen cohesionada de las
familias.

[[FIG035]]
.Visualizaciones gráficas: encontrar sentido a tendencias y patrones escondidos en los conjuntos de datos (Sarah Slobin)
image::figs/incoming/03-ZZ-06.png[scale="96",float="none"]

[[FIG036]]
.Las cifras son gente: el valor de los datos está en las historias individuales que representan (Wall Street Journal)
image::figs/incoming/03-ZZ-07.png[scale="92",float="none"]

Lanzamos el proyecto. Llamé a cada periodista. Les mandé los cuadros, la
idea general y una invitación abierta a encontrar historias que ellos
consideraran significativas, que acercaran la crisis a nuestros
lectores. Necesitábamos una familia pequeña en Ámsterdam y familias más
grandes en España e Italia. Queríamos saber de múltiples generaciones
para ver cómo la historia personal moldea las respuestas.

A partir de aquí, me levantaba temprano para ver mi correo electrónico
teniendo en cuenta la brecha de horarios. Los periodistas respondieron
con temas hermosos, síntesis y sorpresas que no había previsto.

En cuanto a fotografías, sabíamos que queríamos retratos de
generaciones. La visión de Matt era lograr que sus fotógrafos siguieran
a cada miembro de la familia a lo largo de un día en sus vidas. Escogió
periodistas visuales que hubiesen cubierto el mundo, cubierto noticias e
incluso guerras. Matt quería que cada sesión terminara en la cena. Sam
sugirió que incluyéramos los menúes de las comidas.

A partir de allí era cuestión de esperar a ver qué historia contaban las
fotos. Esperar a ver qué decían las familias. Diseñamos el aspecto del
material interactivo. Robé una paleta de colores de una novela de Tintin
y trabajamos la interacción. Y cuando reunimos todo en paneles,
agregamos nuevamente algunos (no todos, algunos) de los cuadros
originales. Lo suficiente para puntuar cada historia, lo suficiente para
endurecer los temas. Los datos se convirtieron en una pausa en la
historia, una manera de bajar un cambio.

[[FIG037]]
.La vida en la Eurozona (Wall Street Journal)
image::figs/incoming/03-ZZ-09.png[float="none"]


Al final, los datos eran la gente; eran las fotografías y las historias.
Era lo que enmarcaba cada narración y provocaba la tensión entre países.

Para cuando publicamos el proyecto, justo antes de fin de año, mientras
todos contemplábamos lo que había en el horizonte, ya conocía a todos
los miembros de las familias por su nombre. Me sigo preguntando cómo
estarán ahora. Y si esto no parece un proyecto de datos, no hay
problema. Porque los momentos que quedaron documentados en la _Vida en
la zona del Euro_, esas historias de sentarse a comer y hablar sobre el
trabajo y la vida con su familia es algo que pudimos compartir con
nuestros lectores. Entender los datos es lo que lo hizo posible.

&mdash; _Sarah Slobin, Wall Street Journal_

=== Cubrir el gasto público con OpenSpending.org

En 2007, Jonathan vino a la Open Knowledge Foundation con una propuesta
de una carilla para un proyecto llamado http://www.wheredoesmymoneygo.org/[Where Does My Money Go] (A dónde va mi dinero,
que apuntaba a facilitarle a los ciudadanos británicos la comprensión de
cómo se gastan los fondos públicos. La intención era que fuera una
demostración de un concepto para un proyecto mayor que representara
visualmente la información pública, basándonos en trabajos pioneros del
Istoype Institute de Otto y Marie Neurath de la década del ‘40.

[[FIG038]]
.¿A dónde va mi dinero? (Open Knowledge Foundation)
image::figs/incoming/03-PP-02.png[float="none"]


El proyecto Where Does My Money Go? permitió a los usuarios explorar
datos públicos de una amplia variedad de fuentes usando herramientas de
código abierto intuitivas. Obtuvimos apoyo para desarrollar un prototipo
del proyecto, y luego recibimos fondos del 4IP de Channel 4, para
convertir esto en una aplicación de la red plenamente funcional. El gurú
del diseño informático, David McCandless (de http://www.informationisbeautiful.net/[Information is Beautiful];
creó varias vistas distintas de los datos que ayudan a la gente a
ubicarse respecto de las grandes cifras, incluyendo el “Analisis del
País y Regional”, que muestra cómo se gastan los fondos en distintas
partes del país, y http://wheredoesmymoneygo.org/dailybread.html[“Daily Bread”] (Pan diario,
que muestra a los ciudadanos un desglose de sus contribuciones fiscales
por día en libras y centavos.

[[FIG039]]
.Calculador impositivo Daily Bread de ¿A dónde va mi dinero? (Open Knowledge Foundation)
image::figs/incoming/03-PP-01.png[float="none"]

En aquel tiempo, el santo grial para el proyecto eran los datos de lo
que se llamaba http://data.gov.uk/dataset/coins[Combined Online Information System] (COINS, Sistema de
Información Combinada Online,
que era la base de datos más abarcativa y detallada de finanzas públicas
británicas. Trabajando con Lisa Evans (antes de que se sumara al equipo
del Datablog en The Guardian), Julian Todd y Francis Irving (conocidos
por Scraperwiki), Martin Rosenbaum (BBC) y otros, presentamos numerosos
pedidos de datos, muchos de ellos con éxito (la saga está parcialmente
documentada por Lisa en el cuadro de texto “Using FOI to Understand
Spending”) (Usar LDI para entender el gasto, en la página 120 de este
manual.)

++++
<?dbfo-need height="1in"?>
++++

Cuando los datos fueron finalmente difundidos a mediados de 2010, fue
considerado un golpe en favor de la transparencia. Se nos dio acceso por
adelantado a los datos para poder cargarlos en nuestra aplicación en la
red y recibimos significativa atención de la prensa cuando se hizo
público este hecho. El día en que se puso a disposición del público,
tuvimos docenas de periodistas que aparecieron en nuestro canal de chat
para debatir y preguntar sobre el hecho, así como averiguar cómo abrir
la aplicación y explorarla (los archivos tenían decenas de gigabytes).
Si bien algunos críticos sostuvieron que la publicación masiva de datos
era tan complicada que en los hechos era http://bit.ly/archive-silicon[oscurecer las cosas de tanta
transparencia], muchos
periodistas valientes se metieron a investigar en los datos para dar a
sus lectores un cuadro sin precedentes del gasto público. The Guardian
http://bit.ly/guardian-coins[transmitió el evento en vivo] en su blog y otros
medios lo cubrieron y ofrecieron conclusiones basadas en los datos.

No tardaron mucho en llegar pedidos y preguntas respecto de proyectos
similares en otros países del mundo. Poco después de lanzar
http://offenerhaushalt.de/[OffenerHaushalt]
-una versión del proyecto para el presupuesto estatal alemán creado por
Friedrich Lendenberg- lanzamos http://openspending.org/[OpenSpending], una versión
internacional del proyecto, que apunta a ayudar a los usuarios a seguir
el gasto público de todo el mundo, un poco como el OpenStreetMap ayudó a
hacer el mapa de accidentes geográficos. Implementamos nuevos diseños
con ayuda del talentoso Gregor Aisch, basados parcialmente en los
diseños originales de David McCandless.

[[FIG0310]]
.OffenerHaushalt, la versión alemana de ¿A dónde va mi dinero? (Open Knowledge Foundation)
image::figs/incoming/03-PP-03.png[float="none"]

Con OpenSpending, hemos trabajado extensamente con periodistas para
adquirir, representar, interpretar y presentar datos de gasto público.
El proyecto es en primer lugar una base de datos enorme del gasto
público –tanto información presupuestaria de alto nivel como gasto
efectivo al nivel de las transacciones- en la que se puede hacer
búsquedas. Sobre esto se ha construido una serie de visualizaciones
tales como "treemaps"(gráficos de rectángulos anidados) y "bubbletrees"
(gráficos de burbujas anidadas). Cualquiera puede cargar los datos de su
municipalidad y producir visualizaciones.

Inicialmente creímos que habría mayor demanda de nuestras
visualizaciones más sofisticadas, pero luego de hablar con
organizaciones de noticias advertimos que había necesidades más básicas
que debían ser satisfechas primero, tales como la capacidad de insertar
tablas dinámicas de datos en sus blogs. Deseosos de alentaras a dar
acceso público a los datos junto con sus historias, también creamos una
aplicación para esto.

Nuestro primer gran lanzamiento fue en la época del primer Festival
Internacional de Periodismo en Perugia. Un grupo de programadores,
periodistas y empleados públicos colaboraron para cargar datos italianos
en la plataforma de OpenSpending, que daba una rica visión de cómo se
dividía el gasto entre las administraciones regionales y locales y
central. Apareció en http://bit.ly/ilfatto-spending[Il Fatto Quotidiano],
http://bit.ly/ilpost-spending[Il Post],
http://bit.ly/lastampa-spending[La Stampa],
http://bit.ly/repubblica-spending[Repubblica],
y http://bit.ly/wired-italy-spending[Wired Italia], así como en http://bit.ly/guardian-italy-spending[The Guardian].

[[FIG0311]]
.Versión italiana de ¿A dónde va mi dinero? (La Stampa)
image::figs/incoming/03-PP-04.png[float="none"]

++++
<?dbfo-need height="1in"?>
++++

En 2011 trabajamos con http://www.publishwhatyoufund.org/[Publish What You Fund] (Publique lo que
financia),
y el http://www.odi.org.uk/[Overseas Development Institute] (Instituto de Desarrollo en el
Extranjero,
para rastrear la ayuda financiera a Uganda de 2003-2006. Esto era nuevo
porque por primera vez se podía ver los flujos de ayuda junto con el
presupuesto nacional, lo que permite ver en qué medida las prioridades
de los donantes están alineadas con las prioridades de los gobiernos.
Hubo algunas conclusiones interesantes, por ejemplo tanto los programas
contra el HIV como la planificación familiar resultaron estar
financiadas casi completamente por donantes externos. Esto fue cubierto
en http://bit.ly/guardian-uganda-viz[The Guardian].

También hemos estado trabajando con ONGs y grupos interesados para
cruzar los datos del gasto con otras fuentes de información. Por
ejemplo, Privacy International se conectó con nosotros trayendo una
larga lista de compañías de tecnología de vigilancia y una lista de
entes que participaron de una feria internacional de la vigilancia muy
famosa, que se conoce como la “fiesta de los que colocan micrófonos
ocultos”. Cruzando nombres de empresas con conjuntos de datos de gasto,
fue posible identificar qué compañías tenían contratos oficiales, los
que a partir de allí podían seguirse a través de pedidos de acceso a la
información al Estado. Esto fue cubierto por http://bit.ly/guardian-surveillance[The Guardian].

Actualmente, estamos trabajando para aumentar el entendimiento de los
datos fiscales por periodistas y el público en general como parte de un
proyecto llamado http://bit.ly/ss-faq[Spending Stories] (Historias de Gastos,
que permite a los usuarios vincular datos de gasto público con historias
relacionadas, para ver las cifras detrás de las noticias y las noticias
a partir de los números.

A través de nuestro trabajo en esta área aprendimos que:

   * Los periodistas a menudo no están acostumbrados a trabajar con datos
en crudo y muchos no consideran tenerlos como base para sus informes.
Basar historias en información cruda sigue siendo una idea relativamente
nueva.
   * Analizar y comprender datos es un proceso que exige mucho tiempo,
incluso si se tiene las capacidades requeridas. Es difícil encajar esto
en un ciclo de noticias de corto plazo, por lo que el periodismo de
datos a menudo es utilizado en proyectos de investigación de más largo
plazo.
   * Los datos difundidos por los gobiernos a menudo están incompletos o
son viejos. Muy a menudo, las bases de datos públicas no pueden ser
usadas para propósitos de investigación sin el agregado de piezas de
información más específicas requeridas a través de las normas de acceso
a la información pública.
   * Grupos de interesados, estudiosos e investigadores a menudo tienen más
tiempo y recursos para realizar investigaciones basadas en datos más
extensas que los periodistas. Puede ser muy fructífero hacer equipo con
ellos.

&mdash; _Lucy Chambers and Jonathan Gray, Open Knowledge Foundation_

++++
<?dbfo-need height="2in"?>
++++

=== Elecciones parlamentarias finlandesas y financiación de campañas

En los últimos meses ha habido juicios relacionados con financiación de
campañas en las elecciones generales finlandesas de 2007.

Después de esos comicios la prensa descubrió que las leyes sobre
publicidad de la financiación de las campañas no tenía efecto sobre los
políticos. Básicamente, se ha utilizado la financiación de campañas para
comprar los favores de políticos que no declararon su financiación tal
como lo ordena la ley finlandesa.

A partir de estos incidentes, las leyes se volvieron más estrictas.
Luego de la elección general de marzo de 2011, Helsingin Sanomat decidió
explorar cuidadosamente todos los datos disponibles sobre financiación
de campañas. La nueva ley estipula que se debe declarar la financiación
electoral, y solo las donaciones de menos de 1500 euros pueden ser
anónimas.


==== 1. Encontrar datos y programadores

Helsingin Sanomat ha organizado hackatones HS Open desde marzo 2011.
Invitamos programadores, periodistas y diseñadores gráficos finlandeses
al sótano de nuestro edificio. Los participantes son divididos en grupos
de 3 personas y se los alienta a desarrollar aplicaciones y
visualizaciones. Hemos tenido alrededor de 60 participantes en cada uno
de nuestros 3 eventos hasta la fecha. Decidimos que los datos de
finanzas de campaña debían ser el centro de HS Open #2, en mayo de 2011.

La Oficina Nacional de Auditoría de Finlandia es la autoridad que lleva
registro de las finanzas de campaña. Esa fue la parte fácil. El jefe de
información, Jaakko Hamunen, construyó un sitio en la red que da acceso
en tiempo real a su base de datos de finanzas de campaña. La Oficina de
Auditoría lo hizo solo en 2 meses después de nuestro pedido.

El sitio http://www.vaalirahoitus.fi/[Vaalirahoitus.fi]  proveerá al
público y la prensa información de las finanzas de campaña para cada
elección a partir de ahora.

[[FIG0312]]
.Finanzas electorales (Helsingin Sanomat)
image::figs/incoming/03-DD.png[float="0"]

==== 2. Tormenta de ideas

Los participantes de HS Open 2 generaron veinte prototipos distintos
respecto de qué hacer con los datos. Puede encontrar todos los
prototipos http://bit.ly/hs-prototype[en nuestro sitio], (texto en
finlandés).

El investigador de bio-informática Janne Peltola señaló que los datos de
las finanzas de campaña se veían parecidos a los datos de genes que
ellos investigan, en términos de contener muchas interdependencias.

En la bio-informática hay una herramienta de código abierto llamada
http://www.cytoscape.org/[Cytoscape] que se
usa para mapear estas interdependencias. Por lo que procesamos los datos
con Cytoscape, y obtuvimos un prototipo muy interesante.

==== 3. Implementar la idea en papel y en la red

La ley de financiación de campañas dice que los miembros electos del
parlamento deben declarar su financiación 2 meses después de las
elecciones. En la práctica esto significó que obtuvimos los datos reales
a mediados de junio. En HS Open solo tuvimos datos de parlamentarios que
habían presentado su información antes del vencimiento del plazo.

También hubo un problema con el formato de los datos. La Oficina
Nacional de Auditoría los proveyó en 2 archivos CSV. Uno contenía el
presupuesto total de las campañas, el otro listaba todos los donantes.
Tuvimos que combinar estos 2 creando un archivo que contenía 3 columnas:
donantes, receptor y monto. Si los políticos habían usado su propio
dinero, en nuestro formato de datos se veía como que el Político A donó
X euros al Político A. Quizás resulte contra-intuitivo, pero funcionó
para Cytoscape.

Cuando los datos fueron depurados y reformateados, lo corrimos con
Cytoscape. Entonces nuestro departamento interactivo hizo un gráfico a
toda página.

Finalmente creamos una hermosa visualización en nuestro sitio. Este no
fue un gráfico de análisis de redes. Queríamos ofrecer a la gente una
manera fácil de explorar los fondos de campaña y quién los dona. La
primera vista muestra la distribución de fondos entre parlamentarios.
Cuando se cliquea en un parlamentario se tiene el desglose de su
financiación. También se puede votar si este donante particular es bueno
o no. La visualización fue hecha por Juha Rouvinen y Jukka Kokko, de una
agencia publicitaria llamada Satumaa.

La versión de la red de la visualización de finanzas de campaña usa los
mismos datos que el análisis de redes.

==== 4. Publicar los datos

Por supuesto que la Oficina Nacional de Auditoría ya publica los datos,
por lo que no hay necesidad de volver a publicarlos. Pero, como habíamos
depurado los datos y les habíamos dado una mejor estructura, decidimos
publicarlos. Damos nuestros datos con una http://creativecommons.org/licenses/by/3.0/[licencia de Creative Commons Attribution].
Después varios programadores independientes hicieron visualizaciones de
los datos, algunas de las cuales hemos publicado.

Las herramientas que usamos para el proyecto fueron Excel y Google
Refine para la depuración y análisis de los datos; Cytoscape para el
análisis de redes; e Illustrator y Flash para las visualizaciones. El
Flash debió haber sido HTML5, pero se nos acabó el tiempo.

¿Qué aprendimos? Quizás la lección más importante fue que las
estructuras de datos pueden ser muy difíciles. Si los datos originales
no están en un formato adecuado, recalcular y convertirlos lleva mucho
tiempo.

=== Hack electoral en tiempo real (Hacks/Hackers Buenos Aires)

[[FIG0313]]
.Elecciones 2011 (Hacks/Hackers Buenos Aires)
image::figs/incoming/03-FF.png[float="none"]


http://elecciones.hhba.info/[Electoral Hack] es un
proyecto de análisis político que visualiza datos de los resultados
provisionales de las elecciones de octubre de 2011 en la Argentina. El
sistema también incluye información de anteriores elecciones y
estadísticas demográficas de todo el país. El proyecto fue actualizado
en tiempo real con información del recuento provisional de las
elecciones nacionales de 2011 en ese país y dio resúmenes de los
resultados. Fue una iniciativa de Hacks/Hackers Buenos Aires con el
analista político Andy Tow, y un esfuerzo colaborativo de periodistas,
programadores, diseñadores, analistas, cientistas políticos e otros
integrantes del capítulo local de Hacks/Hackers.

==== ¿Qué datos usamos?

Todos los datos provienen de fuentes oficiales: la Dirección Nacional
Electoral dio acceso a los datos del recuento provisional por Indra; el
Ministerio del Interior dio información sobre cargos electorales y
candidatos de los distintos partidos políticos; http://yoquierosaber.org/[un proyecto
universitario] dio información biográfica y las plataformas políticas de cada lista
electoral; mientras que la información socio-demográfica provino del
Censo Nacional de 2001 de Población y Vivienda (INDEC), el censo de 2010
(INDEC) y el ministerio de Salud.

==== ¿Cómo se desarrolló?

La aplicación fue generada durante el Hackatón Electoral 2011 de
Hacks/Hackers Buenos Aires, el día antes de las elecciones del 23 de
octubre de 2011. El hackatón tuvo la participación de 30 voluntarios de
una variedad de especialidades. El Hack Electoral fue desarrollado como
una plataforma abierta que podría mejorarse con el tiempo. Para la
tecnología usamos Google Fusion Tables, Google Maps y bibliotecas de
gráficos vectoriales.

Trabajamos en la construcción de polígonos para presentar mapeado
geográfico y demografía electoral. Combinando polígonos en software GIS
y geometrías de tablas públicas en las Tablas de Fusión Google,
generamos tablas con claves correspondientes a la base de datos
electorales del ministerio del Interior, Indra y datos
socio-demográficos de INDEC. A partir de esto creamos visualizaciones en
Google Maps.

Usando el API Google Maps, publicamos varios mapas temáticos
representando la distribución espacial de la votación con distintos
tonos de color, donde la intensidad del color representaba el porcentaje
de votos para varias candidaturas presidenciales en distintos
departamentos administrativos y centros de votación, con particular
énfasis en centros urbanos importantes: de la ciudad de Buenos Aires,
los 24 distritos del Gran Buenos Aires y las ciudades de Córdoba y
Rosario.

Usamos la misma técnica para generar mapas temáticos de elecciones
anteriores, a saber las primarias presidenciales de 2011 y la elección
de 2007, así como la distribución de los datos socio-demográficos, tales
como los de pobreza, mortalidad infantil y condiciones de vida,
permitiendo análisis y comparaciones. El proyecto también mostró la
distribución espacial de las diferencias porcentuales de votos obtenidos
por cada candidatura en la elección general de octubre, comparado con la
elección primaria de agosto.

Luego, usando datos de recuentos parciales, creamos un mapa animado
presentando la anatomía del recuento, en el que se muestra el avance del
mismo desde el cierre de la votación hasta la mañana siguiente.

==== Pros

   * Nos propusimos representar datos y lo logramos. Teníamos la http://infoargentina.unicef.org.ar/[base de
datos socio-demográfica infantil] de UNICEF,
a mano así como la base de datos creada por el yoquierosaber.org de la
Universidad Torcuato Di Tella. Durante el hackatón reunimos un gran
volumen de datos adicionales que terminamos no incluyendo.
   * Claramente el trabajo periodístico y de programación se vio
enriquecido por los estudios académicos. Sin la contribución de Andy Tow
e Hilario Moreno Campos, el proyecto no se hubiera podido realizar.


==== Contras

   * Los datos socio-demográficos que pudimos utilizar no estaban
actualizados (la mayor parte era del censo de 2001) y no era muy
granular. Por ejemplo, no incluía detalles de PBI promedio local,
principal actividad económica, nivel educativo, número de escuelas,
médicos per cápita y muchas otras cosas que hubiera sido bueno tener.
   * Originalmente el sistema debía ser una herramienta que pudiera usarse
para combinar y mostrar datos arbitrariamente, de modo que el periodista
pudiera mostrar fácilmente datos que le interesaran en la red. Pero
tuvimos que dejar esto para otro momento.
   * Dado que el proyecto fue creado por voluntarios en un plazo breve, fue
imposible hacer todo lo que queríamos. De todos modos avanzamos mucho en
el sentido adecuado.
   * Por el mismo motivo, todo el trabajo colaborativo de 30 personas
terminó condensado en un solo programador cuando los datos del gobierno
comenzaron a aparecer, y tuvimos problemas para importar datos en tiempo
real. Estos problemas se resolvieron en cuestión de horas.

==== Implicancias

La plataforma de Hack Electoral tuvo gran impacto en los medios, con
cobertura en televisión, radio, medios impresos y online. Mapas del
proyecto fueron utilizados por varias plataformas de medios durante las
elecciones y en días subsecuentes. Con el paso del tiempo, los mapas y
visualizaciones fueron actualizados, incrementando aún más el tráfico.
El día de la elección, el sitio creado ese mismo día recibió alrededor
de 20.000 visitantes diferentes y sus mapas fueron reproducidos en la
tapa del diario Página/12 2 días consecutivos, así como en artículos en
La Nación. Algunos mapas aparecieron en las ediciones impresas del
diario Clarín. Fue la primera vez en la historia del periodismo
argentino que se utilizó un despliegue interactivo de mapas en tiempo
real. En los mapas centrales se podía ver claramente la victoria
abrumadora de Cristina Fernández de Kirchner por el 54 por ciento de los
votos, desglosada por la saturación de color. También sirvió para ayudar
a los usuarios a entender casos específicos donde candidatos locales
tuvieron victorias por amplio margen en las provincias.

&mdash; _Mariano Blejman, Mariana Berruezo, Sergio Sorín, Andy Tow, and Martín Sarsale from Hacks/Hackers Buenos Aires_

=== Datos en las noticias: WikiLeaks

Comenzó con uno de los integrantes del equipo de periodismo
investigativo preguntando: “¿Ustedes son buenos con las planillas de
cálculo verdad?” Y esta era una enorme planilla de cálculo: 92.201 filas
de datos, cada una conteniendo un análisis de un evento militar en
Afganistán. Estos fueron los registros de http://bit.ly/guardian-warlogs[la guerra de WikiLeaks].
En realidad, la primera parte. Siguieron 2 episodios más: Irak y los
cables. El término oficial fue SIGACTS: la base de datos de Acciones
Significativas de las Fuerzas Armadas de Estados Unidos.

Los registros de guerra de Afganistán –compartidos con The New York
Times y Der Spiegel- fueron periodismo de datos en acción. Lo que
queríamos hacer era permitir a nuestro equipo de periodistas
especializados obtener grandes historias humanas a partir de la
información y queríamos analizarlos para tener el cuadro general,
mostrar cómo iba la guerra realmente.

Desde el comienzo fue central para lo que íbamos a hacer saber que no
publicaríamos toda la base de datos. WikiLeaks ya iba a hacer eso y
queríamos estar seguros de no revelar los nombres de los informantes, o
poner en peligro innecesariamente tropas de la OTAN. Al mismo tiempo,
teníamos que hacer más fácil el uso de los datos para nuestro equipo de
periodistas investigadores encabezados por David Leigh y Nick Davies
(que habían negociado la difusión de los datos con Julian Assange).
También queríamos simplificar el acceso a información clave en el mundo
real, haciéndola tan clara y abierta como pudiéramos.

Los datos llegaron a nosotros como un inmenso archivo Excel, más de
92.201 filas de datos, algunas conteniendo nada o mal formateadas. No le
servía a los periodistas que trataban de buscar historias y era
demasiado grande como para hacer informes significativos.

Nuestro equipo creó una base de datos interna simple usando SQL. Los
periodistas podían a partir de allí buscar por medio de palabras clave o
eventos. De pronto el conjunto de datos se volvió accesible y generar
historias se hizo más fácil.

Los datos estaban bien estructurados: cada evento tenía los siguientes
datos claves: hora, día, descripción, cifras de bajas y, crucialmente,
latitud y longitud detalladas.

También comenzamos a filtrar los datos para ayudarnos a contar una de
las historias claves de la guerra: el aumento de los ataques con DEI
(dispositivos explosivos improvisados), bombas caseras al costado del
camino que son impredecibles y difíciles de combatir. Este conjunto de
datos seguía siendo enorme pero más fácil de manejar. Hubo alrededor de
7500 explosiones o emboscadas con DEI (una emboscada es donde el ataque
se combina, por ejemplo, con fuego de armas pequeñas o de misiles con
granadas) entre 2004 y 2009. Hubo otros 8000 DEI descubiertos y
desactivados. Queríamos ver cómo cambiaban con el tiempo y hacer
comparaciones. Estos datos nos permitieron ver que el sur, donde estaban
las tropas británicas y canadienses, era la zona más golpeada, lo que
confirmaba lo que sabían nuestros corresponsales que habían cubierto la
guerra.

La difusión de los registros de la guerra de Irak en octubre de 2010
descargó otros 391.000 registros de la guerra de Irak en la escena
pública.

Esto estaba en una categoría diferente de la filtración sobre
Afganistán; se puede decir que [line-through]*esto*convirtió a esta en
la guerra más documentada de la historia. Ahora contábamos con cada
detalle menor para analizarlo y desglosarlo. Pero se destaca un factor:
el volumen de las muertes, la mayoría de las cuales eran de civiles.

Tal como en el caso de Afganistán, The Guardian decidió no volver a
publicar la base de datos completa, en gran medida porque no podíamos
estar seguros de que el conjunto no contuviera detalles confidenciales
de informantes y demás.

[[FIG0314]]
.Los registros de guerra de The WikiLeaks (The Guardian)
image::figs/incoming/03-GG.jpg[float="0"]


Pero sí permitimos a nuestros usuarios descargar una planilla de cálculo
que contenía los registros de cada incidente en el que alguien murió,
casi 60.000 en total. Eliminamos el sumario por lo que solo estaban los
datos básicos: el encabezado militar, la cantidad de muertes y la
ubicación geográfica.

También tomamos todos estos incidentes en los que murió alguien y los
pusimos en http://bit.ly/guardian-iraq-map[un mapa usando Google Fusion Tables]. No
era perfecto, pero sí un comienzo para tratar de mapear los patrones de
destrucción que habían devastado Irak.

Los cables se difundieron en diciembre de 2010. Esto entraba en otra
liga, un inmenso conjunto de datos de documentos oficiales: 251.287
despachos, de más de 250 embajadas y consulados estadounidenses. Es un
cuadro único de lenguaje diplomático de EE.UU., incluyendo más de 50.000
documentos que cubren la actual administración Obama. ¿Qué incluían los
datos?

Los cables mismos vinieron vía el inmenso Secret Internet Protocol
Router Network (Red de Ruteo del Protocolo Secreto de Internet),
conocido por la sigla SIPRNet. Es el sistema de Internet mundial militar
de Estados Unidos, que se mantiene separado de la Internet civil común y
es dirigida por el departamento de Defensa en Washington. Desde los
ataques de septiembre de 2001 había habido una iniciativa en Estados
Unidos de vincular archivos de información gubernamental, con la
esperanza de que datos claves de inteligencia ya no quedaran atrapados
en compartimentos estancos o presentados fuera de contexto. Un número
creciente de embajadas de EE.UU. han sido conectados a SIPRNet en la
última década, de modo que pueda compartirse la información militar y
diplomática. Para 2001, había 125 embajadas en SIPRNet; para 2005 la
cifra había crecido a 180 y a esta altura la gran mayoría de las
misiones de EE.UU. en el mundo entero están vinculadas con el sistema,
que es el motivo por el que grueso de estos cables son de 2008 y 2009.
Como escribió David Leigh:

____
Un despacho de embajada marcado como SIPDIS es descargado
automáticamente al sitio clasificado de la embajada. Allí no solo puede
verlo cualquiera en el departamento de Estado, sino cualquiera de las
fuerzas armadas de EE.UU. que tenga acceso de seguridad de nivel
“Secreto”, una clave, y una computadora conectada a SIPRNet.
____

... lo que asombrosamente abarca a 3.000.000 de personas. Hay varias capas
de datos aquí; llegando hasta la clasificación de _SECRET NOFORN_, que
significa que no podrán mostrarse jamás a quienes no sean ciudadanos
estadounidenses. En cambio se supone que son para que los lean
funcionarios en Washington hasta el nivel de la secretaria de Estado,
Hillary Clinton. Los cables normalmente son redactados por el embajador
local o subordinados. No se puede acceder a los documentos de “Secreto
Máximo” y por encima de documento de inteligencia extranjera desde
SIPRNet.

A diferencia de las anteriores entregas, esta era predominantemente de
texto, no cuantificada ni con datos idénticos. Esto es lo que incluía:

Una fuente::

La embajada o el ente que envió los datos

Una lista de receptores::

Normalmente los cables eran enviados a una cantidad de embajadas y
entes.

Un campo de tema::

Una síntesis del cable.

Etiquetas::

Cada cable estaba etiquetado con una cantidad de abreviaturas claves.

Cuerpo del texto::

El cable mismo. Optamos por no publicar estos completos por razones
obvias.

Un detalle interesante de esta historia es cómo los cables casi crearon
filtraciones a demanda. Durante semanas ocuparon el centro de las
noticias al ser publicada; ahora, cada vez que aparece una historia
acerca de algún régimen corrupto o un escándalo internacional, el acceso
a los cables nos da nuevas historias.

El análisis de los cables es una tarea enorme que quizás nunca se
termine por completo.

&mdash; _Esta es una versión editdada de un capítulo publicado en Facts are Sacred: The Power of Data de Simon Rogers, the Guardian (published on Kindle)_


=== Hackatón Mapa76

Inauguramos el capítulo de http://www.meetup.com/HacksHackersBA/[Hacks/Hackers de Buenos Aires]
en abril de 2011. Fuimos anfitriones de 2 encuentros iniciales para
difundir la idea de mayor colaboración entre periodistas y programadores
que incluyó entre 120 y 150 personas en cada evento. Para una tercera
reunión tuvimos un hackatón de 30 horas con 8 personas en una
conferencia de periodismo digital en la ciudad de Rosario, a 300
kilómetros de Buenos Aires.

Un tema recurrente en estas reuniones fue el deseo de recoger grandes
volúmenes de datos de la red y luego representarlos visualmente. Para
ayudar con esto, nació un proyecto llamado Mapa76.info, que ayuda a los
usuarios a extraer datos y luego desplegarlos usando mapas y líneas de
tiempo. Una tarea nada fácil.

[[FIG0315]]
.Mapa76 (Hacks/Hackers Buenos Aires)
image::figs/incoming/03-MM.png[float="none"]

¿Por qué Mapa76? El 24 de marzo de 1976 hubo un golpe de Estado en la
Argentina, que duró hasta 1983. En ese período hubo según se estima
30.000 desaparecidos, miles de muertes y 500 niños nacidos en cautiverio
apropiados por la dictadura militar. Pasados más de 30 años, la cantidad
de gente condenada en la Argentina por crímenes de lesa humanidad
cometidos durante la dictadura llega a 262 personas (septiembre de
2011). En este momento hay 14 juicios en curso y 7 con fecha de comienzo
establecida. Hay 802 personas en varios casos en las cortes.

Estos juicios generan grandes volúmenes de datos que son difíciles de
procesar para los investigadores, periodistas, organizaciones de
derechos humanos, jueces, fiscales y otros. Los datos se producen de
modo distribuido y los investigadores a menudo no recurren a
herramientas de software para ayudarse a interpretarlos. Esto significa
que a menudo no son tenidos en cuenta y las hipótesis son limitadas.
Mapa76 es una herramienta de investigación que da acceso abierto a esta
información con propósitos periodísticos, legales, jurídicos e
históricos.

Para preparar el hackatón creamos una plataforma que programadores y
periodistas pudieran usar para colaborar en el día del evento. Martín
Sarsale desarrolló algunos algoritmos básicos para extraer datos
estructurados de documentos de texto simples. También se usaron algunas
bibliotecas del proyecto DocumentCloud.org, pero no demasiadas. La
plataforma analiza y extrae de manera automática nombres, fechas y
lugares de textos y permite a los usuarios explorar datos claves sobre
distintos casos (por ejemplo, fecha de nacimiento, lugar de arresto,
supuesto lugar de desaparición y así siguiendo).

Nuestra meta era proveer una plataforma para la extracción automática de
datos sobre los juicios contra la dictadura militar en la Argentina.
Queríamos una manera de desplegar automáticamente (o al menos
semi-automáticamente) datos claves relacionados con casos entre 1976 y
1983 basado en evidencias escritas, argumentos y juicios. Los datos
extraídos (nombres, lugares y fechas) son recogidos, almacenados y
pueden ser analizados y refinados por el investigador, así como
explorados usando mapas, líneas de tiempo y herramientas de análisis de
redes.

El proyecto permitirá a periodistas e investigadores, fiscales y
testigos seguir la historia de vida de una persona, incluyendo por
supuesto su cautiverio y posterior desaparición o liberación. Donde
falte información, los usuarios pueden buscar en un vasto número de
documentos que podrían ser de posible relevancia para el caso.

Para el hackatón hicimos un anuncio público a través de http://www.meetup.com/HacksHackersBA/[Hacks/Hackers Buenos Aires],
que entonces tenía alrededor de 200 miembros (en el momento de escribir
este informe hay alrededor de 540). También contactamos muchas
asociaciones de derechos humanos. De la reunión participaron unas
cuarenta personas, incluyendo periodistas, organizaciones de defensa de
los derechos humanos, programadores y diseñadores.

Durante el hackatón identificamos tareas que distintos tipos de
participantes podían desarrollar de forma independiente para ayudar a
que las cosas funcionaran bien. Por ejemplo, pedimos a diseñadores que
trabajaran en una interfaz que combinara mapas y líneas de tiempos,
pedimos a programadores que analizaran maneras de extraer datos
estructurados y logaritmos para eliminar ambigüedades relacionadas con
nombres, y pedimos a periodistas que investigaran qué había pasado con
gente específica, para comparar distintas versiones de historias y
analizar documentos para narrar historias sobre casos particulares.

Probablemente el principal problema que tuvimos después del hackatón fue
que nuestro proyecto era muy ambicioso, nuestros objetivos de corto
plazo exigentes, y es difícil coordinar una red de voluntarios
dispersos. Casi todos los involucrados con el proyecto tenían empleos
que les ocupaban mucho tiempo y muchos participaban además de otros
eventos y proyectos. Hacks/Hackers Buenos Aires tuvo 9 reuniones en
2011.

El proyecto está actualmente en desarrollo activo. Hay un equipo central
de 4 personas trabajando con más de una docena de colaboradores. Tenemos
una http://groups.google.com/group/mapa76-dev/[lista de correo pública]
y un https://github.com/mapa76/[centro de almacenado de código]  a través del
cual cualquiera puede involucrarse en el proyecto.

&mdash; _Mariano Blejman, Hacks/Hackers Buenos Aires_

=== Cobertura de los disturbios en el Reino Unido por el Datablog de The Guardian

Durante el verano de 2011, hubo una oleada de disturbios en el Reino
Unido. En aquel momento, algunos políticos sugirieron que estas acciones
categóricamente no estaban vinculadas con la pobreza y los que saquearon
fueron simplemente criminales. Lo que es más, el primer ministro, junto
con los principales políticos conservadores, culparon a los medios
sociales por causar los disturbios, sugiriendo que había habido
incitación desde estas plataformas y que los disturbios fueron
organizados a través de Facebook, Twitter y Blackberry Messenger (BBM).
Hubo reclamos para cerrar temporariamente los medios sociales. Debido a
que el gobierno no hizo una investigación de por qué se dieron los
disturbios, The Guardian, en colaboración con la London School of
Economics, creó un proyecto innovador para abordar estas cuestiones,
llamado http://www.guardian.co.uk/uk/series/reading-the-riots[Reading the Riots] (Leer los
Disturbios),

[[FIG0316]]
.Los disturbuios en Reino Unido: todos los incidentes verificados (The Guardian)
image::figs/incoming/03-ZZ.png[float="0"]

El diario usó periodismo de datos a gran escala para permitir al público
comprender mejor quién saqueaba y por qué. También trabajaron con otro
equipo de académicos, encabezados por el profesor Rob Procter de la
universidad de Manchester para entender mejor el rol de los medios
sociales, que The Guardian mismo había usado abundantemente para sus
informes durante los disturbios. El equipo de _Reading the Riots_ fue
encabezado por Paul Lewis, el Editor de Proyectos Especiales de The
Guardian. Durante los disturbios Paul reportó desde el lugar de los
eventos en ciudades de toda Inglaterra (fundamentalmente a través de su
cuenta de Twitter @paullewis). Este segundo equipo trabajó a partir de
26.000.000 de tweets sobre los disturbios puestos a disposición por
Twitter. El objetivo principal de este trabajo con los medios sociales
fue ver cómo circulan los rumores en esa red social, la función que
tienen distintos usuarios/actores en la propagación y difusión de flujos
de información, para ver si se usó la plataforma para incitar, y para
examinar otras formas de organización.

En términos del uso del periodismo de datos y visualizaciones, es útil
distinguir 2 períodos claves: el período de los disturbios mismos y las
maneras en que los datos ayudaron a narrar historias mientras se
desarrollaban los disturbios; y luego un segundo período de
investigación mucho más intensa con 2 conjuntos de equipos académicos
trabajando con The Guardian, para recolectar datos, analizarlos, y
escribir informes con análisis de fondo sobre lo descubierto. Los
resultados de la primera fase del proyecto _Reading the Riots_ fueron
publicados durante una semana de cobertura extensiva a comienzos de
diciembre de 2011. A continuación aparecen algunos ejemplos claves de
cómo se usó el periodismo de datos durante ambos períodos.

==== Primera fase: los disturbios mientras sucedían

Usando mapas simples, el equipo de datos de The Guardian mostró
http://bit.ly/guardian-riots-map[localizaciones de lugares de disturbios confirmados]
y combinando datos de pobreza con http://bit.ly/guardian-riots-poverty[los lugares donde se dieron los disturbios],
se comenzó a dejar sin sustento el discurso político central de que no
había ningún vínculo con la pobreza. En ambos ejemplos se utilizaron
herramientas de mapeo preexistentes y, en el segundo caso, se combinaron
datos de ubicación con otro conjunto de datos para comenzar a establecer
otras conexiones y vínculos.

En relación al uso de medios sociales durante los disturbios (en este
caso, Twitter), el diario creó http://bit.ly/guardian-riots-twitter[una visualización de hashtags]
relacionadas con los disturbios usadas durante este período,
lo que destacó que Twitter fue usado principalmente para responder a
disturbios en vez de para organizar a gente para saquear, con
#riotcleanup, la campaña espontánea para limpiar las calles después de
los disturbios, mostrando el salto más significativo durante el período
de los disturbios.

==== Fase 2: análisis de los disturbios

Con relación al momento en que el diario informó sus conclusiones luego
de meses de investigaciones intensivas trabajando en estrecha
colaboración con 2 equipos académicos, se destacan 2 visualizaciones que
han sido ampliamente debatidas. La primera, http://bit.ly/guardian-riots-commute[un video corto],
muestra los resultados de combinar los lugares conocidos donde la gente
protagonizó disturbios con sus lugares de vivienda y mostrando lo que se
llamó “viaje a los disturbios”. Aquí el diario trabajó con un
especialista en mapeo de transporte, ITO World, para hacer un modelo de
la ruta más probable utilizada por quienes protagonizaron los disturbios
al dirigirse a los distintos lugares donde saquearon, lo que destaca
patrones diferentes para distintas ciudades, con viajes largos en
algunas de ellas.

La segunda se refiere a las maneras en que se extienden los rumores en
Twitter. En debate con el equipo académico, se escogieron 7 rumores para
su análisis. El equipo académico entonces recolectó todos los datos
relacionados con cada rumor y diseñó un código que identifica cada tweet
de acuerdo a los 4 códigos principales: gente que simplemente repite el
rumor (afirma algo), lo rechaza (afirma algo contrario), lo cuestiona
(interrogación) o simplemente lo comenta (comentario). Todos los tweets
fueron codificados por triplicado y los resultados http://bit.ly/guardian-riots[fueron visualizados]
 por el equipo interactivo de The Guardian. El equipo de The Guardian http://bit.ly/guardian-riots-twitter-interactive[escribió
acerca de cómo construyó las visualizaciones].


++++
<?dbfo-need height="1in"?>
++++

Lo llamativo de esta visualización es que muestra de manera potente lo
que es muy difícil de describir y que es la naturaleza viral de los
rumores y las maneras en que se desarrolla su ciclo vital a lo largo del
tiempo. El rol de los principales medios es evidente en algunos de estos
rumores (por ejemplo, rechazándolos abiertamente, o confirmándolos
rápidamente como noticias), al igual que la naturaleza correctiva de
Twitter mismo en términos de responder a tales rumores. Esta
visualización no solo ayudó mucho a narrar la historia, sino que también
dio una visión real de cómo funcionan los rumores en Twitter, lo que
aporta información útil para responder a eventos futuros.

Lo que resulta claro a partir del último ejemplo es la poderosa sinergia
entre el diario y un equipo académico capaz de un análisis profundo de
2.600.000 de tweets producidos en los disturbios. Si bien el equipo
académico creó un conjunto de herramientas para hacer su análisis, ahora
están trabajando para hacer que estas estén disponibles para cualquiera
que desee utilizarlas ofreciendo un centro de trabajo para su análisis.
Combinado con la explicación de cómo hacer las cosas aportada por el
equipo de The Guardian, constituye un estudio de caso que es útil porque
muestra cómo el análisis de medios sociales y las visualizaciones pueden
ser usadas para narrar historias importantes.

&mdash; _Farida Vis, University of Leicester_

=== Evaluaciones de escuelas de Illinois

Cada año la Dirección Estadual de Educación de Illinois difunde
“evaluaciones” de escuelas, datos sobre la demografía y el desempeño de
todas las escuelas públicas de Illinois. Es un conjunto de datos masivo.
El informe de este año tenía 9500 columnas de ancho. El problema con esa
cantidad de datos es decidir qué presentar. (Como sucede con cualquier
proyecto de software, lo difícil no es crear el software, sino crear el
software correcto).

Trabajamos con los periodistas y el editor de Educación para escoger los
datos más relevantes. (hay muchos datos que parecen interesantes, pero
que un periodista le dirá que en realidad son falsos o engañosos).

También encuestamos y entrevistamos gente con hijos en edad escolar en
nuestra redacción. Hicimos esto por la existencia de una brecha de
empatía: ninguno de los miembros del equipo de aplicaciones de noticias
tiene chicos en edad escolar. Por esta vía descubrimos muchas cosas
acerca de nuestros usuarios y de la practicidad (o falta de ella) de la
versión anterior de nuestro sitio sobre escuelas.


[[FIG0317]]
.2011 Los boletines de las escuelas de Illinois (Chicago Tribune)
image::figs/incoming/03-EE.png[float="none"]

Nos orientamos a diseñar para un par de usuarios y casos de uso
específicos:

* Padres con un niño en la escuela que quieren saber cómo es el
desempeño de su escuela
* Padres que trataban de determinar dónde les convenía vivir, dado que
la calidad de las escuelas a menudo tiene un gran impacto sobre esa
decisión

La primera vez el sitio sobre escuelas fue un proyecto de 2 diseñadores
de alrededor de 6 semanas. La actualización de 2011 fue un proyecto de 2
diseñadores de 4 semanas. (en realidad hubo 3 personas trabajando
activamente en el proyecto más reciente, pero ninguna de ellas era
full-time, por lo que equivalen a 2).

++++
<?dbfo-need height="1in"?>
++++

Una pieza clave de este proyecto fue el diseño de la información. Aunque
presentamos mucho menos datos de los que hay disponibles, siguen siendo
_muchos_ datos, y hacerlos digeribles fue un desafío. Por suerte,
pudimos tomar alguien prestado de nuestra mesa de gráficos, un diseñador
especializado en presentar información complicada. Nos enseñó mucho
acerca del diseño de cuadros y, en general, nos guió para producir una
presentación que es legible, pero no subestima la capacidad o el deseo
del lector de entender las cifras.

El sitio fue creado con Python y Django. Los datos están almacenados en
MongoDB: los datos sobre escuelas son heterogéneos y jerárquicos, lo que
hace que no funcionen bien en una base de datos relacional (de otro modo
probablemente hubiésemos usado PostgreSQL).

Por primera vez experimentamos con el marco de interfaz de usuario
Bootstrap de Twitter en este proyecto y los resultados nos dejaron
contentos. Los gráficos fueron dibujados con Flot.

La aplicación también alberga las muchas historias sobre evaluación
escolar que hemos escrito. En ese sentido es una especie de portal;
cuando hay una nueva historia de evaluación de escuelas la ubicamos a la
cabeza de la aplicación, junto con listas de escuelas que son relevantes
para la historia (y cuando aparece una nueva historia, a los lectores
de http://www.chicagotribune.como/[chicagotribune.com]
se los reorienta hacia la aplicación, no el artículo).

Los primeros indicios muestran que a los lectores les encanta la
aplicación sobre las escuelas. La retroalimentación que hemos recibido
en gran medida ha sido positiva (o al menos constructiva) y la cantidad
de visitas es enorme. Como premio, estos datos mantendrán su interés
todo un año, por lo que aunque prevemos que se reducirán las visitas al
ir desapareciendo las historias sobre escuelas en la página de inicio,
nuestra experiencia nos indica que los lectores recurren a esta
aplicación todo el año.

Algunas ideas claves que surgieron del proyecto son:

* Los diseñadores gráficos son nuestros amigos. Son buenos para hacer
digerible información compleja.
* Hay que pedir ayuda a la redacción. Este es el segundo proyecto para
el que realizamos una encuesta y entrevistas en la redacción, y es una
gran manera de tener opiniones de gente reflexiva que, como nuestro
público, es diversa en cuanto a sus inclinaciones y en general se siente
incómoda con las computadoras.
* ¡Muestre su trabajo! Gran parte de la retroalimentación tomó la forma
de pedidos de los datos que usó la aplicación. Pusimos muchos datos a
disposición del público vía una API, y pronto difundiremos todo lo que
no incluimos inicialmente.

&mdash; _Brian Boyer, Chicago Tribune_


=== Facturación de hospitales

Periodistas de investigación de http://californiawatch.org/[California Watch]
recibieron informes de que una gran cadena de hospitales de ese estado
norteamericano podía estar haciendo trampas sistemáticamente contra el
programa federal Medicare que paga los tratamientos médicos de
estadounidenses de 65 años o más. La trampa denunciada se llama
_upcoding_ (subir el código), que significa reportar pacientes con
problemas más complicados de salud –con reembolsos más elevados- que los
reales. Pero una fuente clave era un sindicato que estaba enfrentado con
la administración de la cadena de hospitales, y el equipo de California
Watch sabía que era necesaria una verificación independiente para que la
historia tuviera credibilidad.

Por suerte, el departamento de Salud de California tiene registros
públicos que dan información muy detallada sobre cada caso tratado en
todos los hospitales del estado. Las 128 variables incluyen hasta 25
códigos de diagnóstico del manual de “Clasificación Estadística
Internacional de Enfermedades y Problemas de Salud Relacionados”
(conocido comúnmente como ICD-9) publicado por la Organización Mundial
de la Salud (OMS). Aunque no se identifica a los pacientes por su
nombre, si aparece la edad del paciente, cómo se pagó por el tratamiento
y qué hospital lo trató. Los periodistas advirtieron que con estos
registros, podían ver si los hospitales propiedad de la cadena estaban
informando ciertas enfermedades inusuales en proporciones
significativamente mayores que en otros hospitales.

[[FIG0318]]
.Kwashiorkor (California Watch)
image::figs/incoming/03-AA.png[float="0"]

Los conjuntos de datos eran grandes: casi 4.000.000 de registros por
año. Los periodistas querían estudiar los registros de 6 años para ver
cómo cambiaban los patrones a lo largo del tiempo. Pidieron los datos al
ente estatal; llegaron en varios CD-ROM que se copiaron fácilmente a una
computadora de escritorio. El periodista que hizo el análisis de los
datos usó un sistema http://www.sas.com/[llamado SAS] para trabajar con los datos.
SAS es muy poderoso (permitiendo el análisis de muchos millones de
registros) y es usado por numerosos entes estatales, incluyendo el
departamento de Salud de California, pero es costoso. Se pudo haber
hecho el mismo tipo de análisis usando una variedad de herramientas de
bases de datos, tales como el Access de Microsoft o http://www.mysql.com/[MySQL] de código abierto.

Con los datos y los programas para estudiarlos, encontrar patrones
sospechosos fue relativamente simple. Por ejemplo, una acusación era que
la cadena estaba informando de gente con diversos grados de desnutrición
con porcentajes mucho más altos que lo que se veía en otros hospitales.
Usando SAS, el analista de datos extrajo tablas de frecuencia que
muestran la cantidad de casos de desnutrición informados cada año por
cada uno de los más de 300 hospitales de agudos de California. Las
tablas de frecuencia luego eran importadas a Microsoft Excel para un
análisis más fino de los patrones de cada hospital; la capacidad de
Excel de ordenar, filtrar y calcular tasas a partir de las cifras en
bruto facilitó la tarea de encontrar patrones.

Eran particularmente llamativos los informes de una enfermedad llamada
Kwashiorkor, un síndrome de deficiencia de proteínas que se ve casi
exclusivamente en infantes que mueren por desnutrición en países en
desarrollo afectados por hambrunas. Pero la cadena estaba informando que
sus hospitales diagnosticaban Kwashiorkor entre personas mayores de
California en cantidades 770 veces mayores que http://bit.ly/californiawatch-malnutrition[el promedio de los
hospitales del estado].


Para otras historias, los análisis usaron técnicas similares para
examinar las cantidades reportadas de http://bit.ly/californiawatch-rare[enfermedades como septicemia,
encefalopatía, hipertensión maligna y desórdenes nerviosos autonómicos].
Otro estudio analizó las denuncias de que la cadena estaba admitiendo en
internación, provenientes de sus salas de emergencias, porcentajes
http://bit.ly/californiawatch-chains[inusualmente elevados de pacientes de Medicare],
cuya fuente de pagos de cuidados hospitalarios es más segura que lo que
sucede con muchos otros pacientes atendidos en salas de emergencias.

En síntesis, historias como estas son posibles cuando se usan datos para
producir evidencias que evalúan de forma independiente acusaciones de
fuentes que pueden tener sus propios objetivos. Estas historias también
son un buen ejemplo de la necesidad de leyes de registro público
robustas; el motivo por el que el estado requiere que los hospitales
informen estos datos es para que se pueda hacer este tipo de análisis,
ya sea por el propio estado o por académicos, investigadores o incluso
ciudadanos periodistas. El tema de estas historias es importante porque
examina si se está gastando como corresponde millones de dólares de
fondos públicos.

&mdash; _Steve Doig,  Walter Cronkite School of Journalism, Arizona State University_

=== Crisis de los geriátricos

// Commented out until clarification on license received
//[[FIG0319]]
//._Private care faces crises_ (Financial Times)
//image::figs/incoming/03-NN.png[float="none"]


Una http://on.ft.com/care-home-crisis[investigación del Financial Times]
sobre geriátricos sacó a luz como algunos inversores de capitales
privados convierten el cuidado de las personas mayores en una máquina de
obtener ganancias, y destacó los costos mortales de un modelo de
negocios que promueve las ganancias por encima de los cuidados.

El análisis se hizo en un buen momento, porque los problemas financieros
de Southern Cross, entonces el mayor operador de geriátricos del país,
estaban llegando a un punto álgido. El gobierno había impulsado durante
décadas la privatización en el sector de los geriátricos y seguía
aplaudiendo al sector privado por sus prácticas de negocios astutas.

Nuestra investigación comenzó con el análisis de datos que obtuvimos del
ente regulador británico a cargo de inspeccionar los geriátricos. La
información era pública, pero se requirió mucha persistencia para
conseguir los datos en una forma que fuera utilizable.

Los datos incluían calificaciones (ahora eliminadas) del desempeño de
geriátricos individuales y un desglose de si eran privados, estatales o
sin fines de lucro. La Comisión de Calidad de Cuidados (CQC) hasta junio
de 2010 calificaba a los geriátricos de acuerdo a su calidad (0
estrellas = mala, 3 estrellas = excelente).

El primer paso requirió mucha depuración de datos, ya que la información
provista por la Comisión de Calidad de Cuidados contenían
categorizaciones que no eran uniformes. Esto se hizo primordialmente
usando Excel. También determinamos –a través de investigaciones de
escritorio y telefónicas- si había geriátricos particulares que fueran
propiedad de grupos de capitales privados. Antes de la crisis
financiera, el sector de los geriátricos era un imán para el capital
privado e inversores inmobiliarios, pero varios de ellos -tales como
Southern Cross- habían comenzado a tener serias dificultades
financieras. Queríamos establecer qué efecto, si es que había alguno,
tenía el hecho de la presencia de capitales privados en la calidad de
los cuidados.

Un conjunto de cálculos relativamente simples con Excel nos permitieron
establecer que los geriátricos sin fines de lucro y estatales en
promedio tenían un desempeño significativamente mejor que los del sector
privado. Algunos grupos de geriátricos de capitales privados funcionaban
por encima del promedio y otros por debajo.

Junto con informes in situ, estudios de casos de abandono, un análisis
profundo de las fallas de las políticas regulatorias, así como otros
datos sobre niveles de paga, tasas de rotación, etc., nuestro análisis
nos permitió armar un cuadro del estado real de los geriátricos.

Algunos consejos:

* Asegúrese de tomar notas de cómo manipula los datos originales.
* Tenga una copia de los datos originales y nunca los modifique.
* Verifique y vuelva a verificar los datos. Haga el análisis varias
veces (si es necesario, a partir de cero).
* Si menciona compañías o individuos particulares, deles derecho a
réplica.

&mdash; _Cynthia O'Murchu, Financial Times_

=== El teléfono que lo dice todo

La comprensión de la mayoría de las personas de lo que puede hacerse con
los datos que nos proveen nuestros celulares es teórica; había pocos
ejemplos de la vida real. Es por eso que Malte Spitz del partido Verde
Alemán decidió publicar sus propios datos. Para acceder a la información
tuvo que presentar una demanda contra el gigante de las
telecomunicaciones Deutsche Telekom. Los datos, contenidos en un inmenso
documento de Excel, fueron la base para el mapa interactivo del Zeit
Online. Cada una de las 35.831 filas de la planilla de cálculo
representa una instancia en la que el teléfono de Spitz transfirió
información en un período de medio año.

Vistas por separado, cada pieza de datos es casi inofensiva. Pero
tomadas de conjunto aportan lo que los investigadores llaman un perfil
de llamadas: un claro cuadro de los hábitos y preferencias de una
persona y por cierto de su vida. Este perfil revela cuándo Spitz
caminaba por la calle, cuánto tomó un tren, cuándo estaba en un avión.
Muestra que trabaja principalmente en Berlín y qué ciudades visitó.
Muestra cuándo estaba despierto y cuándo dormía.

[[FIG0320]]
.El teléfono que lo dice todo (Zeit Online)
image::figs/incoming/03-BB.png[scale="93",float="none"]

El conjunto de datos de Deutsche Telekom mantenía en privado una parte
del registro de los datos de Spitz, a saber, a quién llamó y quién lo
llamó a él. Ese tipo de información no solo podría infringir la
privacidad de mucha otra gente relacionada con él, también –aunque los
números estuviesen encriptados- revelaría demasiado acerca de Spitz
(pero los agentes del gobierno en el mundo real tendrían acceso a esta
información).

Pedimos a Lorenz Matzat y Michael Kreil de OpenDataCity que exploraran
los datos y encontraran una solución para la presentación visual. “Al
principio usamos herramientas como Excel y Fusion Tables para comprender
los datos. Luego comenzamos a desarrollar una interfaz del mapa que
permitiera al público interactuar con los datos de un modo no lineal”,
dijo Matzat. Para ilustrar hasta qué punto pueden obtenerse detalles de
la vida de alguien a partir de estos datos almacenados, se le sumó
información del dominio público acerca de su actividad (Twitter,
entradas en blogs, información partidaria como entradas en el calendario
público de su sitio en la red). Es el tipo de proceso que cualquier buen
investigador usaría probablemente para hacer el perfil de una persona en
observación. Junto con los gráficos del propio Zeit Online y los del
equipo de investigación y desarrollo, se creó una gran interfaz para
navegar: apretando el botón de play se inicia un viaje a través de la
vida de Malte Spitz.

Luego de un lanzamiento muy exitoso del proyecto en Alemania, advertimos
que recibíamos muchísimo tráfico de fuera de Alemania y decidimos crear
una versión en inglés de la aplicación. Luego de recibir el premio
Grimme Online Alemán, el proyecto recibió un premio ONA en septiembre de
2011, lo que fue la primera vez que lo recibía un sitio de noticias
alemán. Todos los datos están disponibles en una http://bit.ly/zeitonline-data[planilla de cálculo de
Google Docs]. Lea la historia http://www.zeit.de/datenschutz/malte-spitz-data-retention[en Zeit Online].

&mdash; _Sascha Venohr, Zeit Online_

=== Tasas de reprobación de distintos modelos de auto en la prueba MOT

En enero de 2010 la BBC obtuvo datos sobre aprobaciones y rechazos en la
prueba del Ministerio de Transporte (MOT, Ministry of Transport Test)
para distintas marcas y modelos de autos. Esta es la prueba que evalúa
si un auto es seguro y está en condiciones para andar por la calle; todo
auto de más de 3 años tiene que pasar una prueba MOT anual.

Obtuvimos los datos bajo la ley de acceso a la Información luego de una
larga batalla con VOSA, el ente del departamento de Transporte que
supervisa el sistema MOT. VOSA rechazó nuestro pedido de estas cifras
con el argumento de que violaría la confidencialidad comercial. Sostuvo
que podría _causar daño comercial_ a fabricantes de vehículos con altas
tasas de rechazo. Entonces apelamos al Comisionado de información, que
dictaminó que dar a conocer la información iría en favor del interés del
público. Entonces VOSA entregó los datos, 18 meses después de que los
pidiéramos.

Analizamos las cifras, concentrándonos en los modelos más populares y
comparando autos de la misma antigüedad. Esto mostró grandes
discrepancias. Por ejemplo, entre los autos de 3 años de antigüedad, 28%
de los Renault Mégane no aprobaron su MOT, en contraste con solo el 11%
de los Toyota Corolla. Las cifras se difundieron por televisión, radio y
online.


[[FIG0321]]
.Difusión de las tasas de rechazo en la prueba MOT (BBC)
image::figs/incoming/03-CC.png[float="none"]


Nos entregaron los datos en la forma de un documento PDF de 1200
páginas, que tuvimos que convertir en planilla de cálculo para hacer el
análisis. Además de informar nuestras conclusiones, publicamos la
planilla de cálculo Excel (con más de 14.000 líneas de datos) en el
sitio de BBC News http://bbc.in/mot-failure-rates[junto con nuestra historia]. Esto
permitió el acceso a los datos en formato usable a todos.

El resultado fue que entonces otros usaron estos datos para sus propios
análisis, que nosotros no tuvimos tiempo de hacer por el apuro de
difundir la historia rápidamente (y que en algunos casos hubiera
superado nuestra capacidad técnica de aquel momento). Esto incluyó el
examen de las tasas de rechazo para autos de otras antigüedades,
comparar los registros de fabricantes en vez de modelos individuales y
crear bases de datos para buscar los resultados de modelos individuales.
Agregamos vínculos a estos sitios en nuestra historia online, de modo
que los lectores pudieran conocer estos trabajos.

Esto ilustra algunas de las ventajas de publicar los datos en crudo
junto con una historia basada en datos. Puede haber excepciones (por
ejemplo si piensa usar los datos para otras historias posteriores y
quiere quedárselos mientras tanto), pero en general publicar los datos
tiene varios beneficios importantes:

* Su trabajo es descubrir cosas y contarle a los ciudadanos. Si se tomó
el trabajo de obtener los datos es parte de su trabajo difundirlos.
* Otras personas pueden descubrir cuestiones de interés significativo
que usted no vio o simplemente detalles que les importan a ellos, aunque
no le importaran lo suficiente a usted como para incluirlos en su
historia.
* Otros pueden basarse en su trabajo para desarrollar un análisis más
detallado, o usar distintas técnicas para presentar o visualizar las
cifras, usando sus propias ideas o capacidades técnicas que pueden
sondear los datos de modo productivo y de maneras alternativas.
* Es parte de incorporar la rendición de cuentas y la transparencia al
proceso periodístico. Otros pueden entender sus métodos y verificar su
trabajo si quieren.

&mdash; _Martin Rosenbaum, BBC_


=== Subsidios a colectivos en Argentina

Desde 2002 los subsidios para el sistema de transporte público de
pasajeros en la Argentina han estado creciendo de modo exponencial,
rompiendo un record cada año. Pero en 2011, luego de ganar las
elecciones, el nuevo gobierno argentino anunció reducciones de los
subsidios para los servicios públicos a partir del mes de diciembre de
ese año. Al mismo tiempo, decidió transferir la administración de líneas
locales de ómnibus y del subte al Gobierno de la Ciudad de Buenos Aires.
Dado que no se ha clarificado la transferencia de subsidios a este
gobierno municipal y hay falta de fondos locales para garantizar la
seguridad el sistema de transporte, el Gobierno porteño rechazó esta
decisión.

Mientras esto sucedía, junto con mis colegas en La Nación nos reunimos
por primera vez para discutir cómo iniciar nuestra propia operación de
periodismo de datos. Nuestro editor de la sección financiera sugirió que
los datos sobre subsidios publicados http://www.transporte.gov.ar/[por la secretaría de Transporte] sería un
buen desafío para comenzar, considerando que era muy difícil
encontrarles sentido debido al formato y la terminología.

Las malas condiciones del sistema de transporte público afectan la vida
de más de 5800000 pasajeros diarios. Demoras, huelgas, desperfectos de
vehículos, o incluso accidentes suceden a menudo. Por tanto, decidimos
analizar a dónde van los subsidios para el sistema de transporte público
en la Argentina y poner estos datos a disposición de todos los
ciudadanos argentinos por medio de un “Explorador de Subsidios del
Transporte”, que actualmente está en construcción.

[[FIG0322]]
.El explorador de subsidios al transporte (La Nación)
image::figs/incoming/03-LL-01.jpg[float="0"]

Comenzamos por calcular cuánto reciben cada mes las compañías de ómnibus
de parte del Estado. Para hacerlo, tomamos los datos publicados en el
http://www.transporte.gov.ar/content/subsidios-sistau/[sitio del departamento de Transporte],
donde se publican desde 2006 más de 400 PDF conteniendo pagos mensuales
en efectivo a más de 1300 compañías.

[[FIG0323]]
.Ranking de empresas de transporte subsidiadas (La Nación)
image::figs/incoming/03-LL-02.jpg[float="0"]

Formamos equipo con un programador experimentado para desarrollar un
recopilador de información de modo de automatizar la descarga regular y
la conversión de estos PDF en archivos de Excel y Base de datos. Estamos
usando el conjunto de datos resultante con más de 285.000 registros para
nuestras investigaciones y visualizaciones, tanto en versión impresa
como online. Además, estamos difundiendo estos datos en formato legible
por computadora para que todo argentino pueda utilizarlos y
compartirlos.

El siguiente paso fue identificar cuánto le cuesta en promedio al
gobierno el mantenimiento mensual de un vehículo de transporte público.
Para descubrirlo consultamos otro sitio oficial, el http://www.cnrt.gov.ar/index2.htm[de la Comisión
Nacional de Regulación del Transporte],
responsable de la regulación del transporte en la Argentina. En este
sitio encontramos una lista de compañías de ómnibus que poseen en total
9000 vehículos. Desarrollamos un normalizador para permitirnos conciliar
los nombres de las compañías de transporte y hacer referencias cruzadas
entre los 2 conjuntos de datos.

Para continuar, necesitábamos el número de registro de cada vehículo. En
el sitio de la CNRT encontramos una lista de vehículos discriminados por
línea de colectivo y compañía, con sus números de licencia. En
Argentina, estos registros están compuestos de letras y cifras que se
corresponden con la edad del vehículo. Por ejemplo, mi auto tiene el
número de registro IDF234, y la “I” corresponde a marzo-abril 2011.
Hicimos el cálculo inverso a partir de las licencias de los ómnibus
propiedad de las compañías registradas, para descubrir la edad promedio
de los ómnibus y mostrar cuánto dinero recibe cada compañía y finalmente
comparar los montos en base a la edad promedio de sus vehículos.

En medio de este proceso, cambió misteriosamente el contenido de los PDF
oficiales con los datos, aunque las URL y los nombres de los archivos no
se modificaron. En algunos PDF ahora faltaban los “totales” verticales,
lo que hace imposible cruzar los mismos en todo el período investigado,
2002-2011.

Llevamos este caso a un hackatón organizado por Hacks/Hackers en Boston,
donde el programador Matt Perry generosamente creó lo que llamamos el
“Espía de PDF”. Esta aplicación ganó la categoría “más intrigante” en
ese evento. El http://gristlabs.com/2011/09/24/pdfspy/[Espía de PDFs]
apunta a una página web llena de PDF y verifica si el contenido dentro
de los PDF ha cambiado. “Nunca serán engañados nuevamente por la
supuesta “transparencia del gobierno’”, escribe Matt Perry.

[[FIG0324]]
.Comparación de antigüedad de flotas con el monto de dinero que reciben del Estado (La Nación)
image::figs/incoming/03-LL-03.jpg[float="0"]


==== ¿Quién trabajó en el proyecto?

Un equipo de 7 periodistas, programadores y un diseñador interactivo
durante 13 meses.

Las capacidades que necesitamos para este proyecto fueron:

   * Periodistas con conocimiento sobre cómo funcionan los subsidios para
el sistema de transporte público y cuáles eran los riesgos; conocimiento
del mercado de compañías de ómnibus.
   * Un programador capacitado en recopilar datos de la red, su análisis,
normalización y extracción de datos de PDF a planillas de cálculo Excel.
   * Un especialista en estadística para el análisis de los datos y los
distintos cálculos.
   * Un diseñador para producir las visualizaciones interactivas de datos.

==== ¿Qué herramientas utilizamos?

Usamos VBasic para aplicaciones, Excel Macros, Tableau Public y la
Plataforma Abierta de datos Junar, así como Ruby on Rails, la API de
cuadros Google, y Mysql para el Explorador de Subsidios.

El proyecto tuvo gran impacto. Hemos tenido decenas de miles de visitas
y la investigación apareció en la primera plana de la edición impresa de
La Nación.

El éxito de este primer proyecto de periodismo de datos nos ayudó
internamente para argumentar en favor de la creación de una operación de
datos que cubra periodismo de investigación y provea servicio al
público. Esto resultó en Data.lanacion.com.ar, una plataforma donde
publicamos datos abiertos sobre distintos tópicos de interés público en
formatos procesables por computadora.

&mdash; _Angélica Peralta Ramos, La Nación (Argentina)_


=== Ciudadanos periodistas de datos

No solo las grandes redacciones pueden trabajar en historias basadas en
datos. Las mismas capacidades que son útiles para los periodistas de
datos también pueden ayudar a ciudadanos periodistas a acceder a datos
sobre sus localidades y convertirlos en historias.

Ese fue la principal motivación para el proyecto de medios ciudadanos de
http://amigosdejanuaria.wordpress.com/[Amigos de Januária],
en Brasil, que recibió un subsidio (http://rising.globalvoicesonline.org/[de Rising Voices],
la rama de extensión de http://globalvoicesonline.org/[Global Voices Online]
y apoyo adicional de http://www.article19.org/[la organización Article 19]. Entre septiembre
y octubre de 2011, un grupo de jóvenes residentes de un pequeño pueblo
localizado al norte del estado de Minas Gerais, una de las regiones más
pobres de Brasil, fue capacitado en técnicas básicas de periodismo y
control de presupuesto. También aprendió cómo hacer pedidos de acceso a
la información y cómo obtener información pública de bases de datos
oficiales en internet.

[[FIG0325]]
.El proyecto de medios ciudadanos Amigos de Januária da capacidades claves a los ciudadanos para convertirlos en periodistas de datos
image::figs/incoming/03-XX.jpg[float="0"]

Januária, un pueblo de aproximadamente 65.000 residentes, también es
conocido por las fallas de sus políticos locales. En 3 períodos de 4
años tuvo 7 alcaldes diferentes. Casi todos fueron removidos de sus
funciones por mal desempeño en sus administraciones, incluyendo
acusaciones de corrupción.

Los pequeños pueblos como Januária a menudo no atraen la atención de los
medios brasileños, que tienden a concentrarse en ciudades mayores y
capitales de estado. Sin embargo hay una oportunidad para que los
residentes de pequeños pueblos se conviertan en aliados potenciales en
el monitoreo de la administración pública, porque conocen mejor que
nadie los desafíos cotidianos que enfrentan las comunidades locales.
Teniendo a Internet como otro aliado importante, los residentes ahora
pueden acceder mejor a datos del presupuesto y otra información local.

Luego de participar de 12 talleres, algunos de los nuevos ciudadanos
periodistas de Januária comenzaron a demostrar cómo este concepto de
acceder a datos públicos en pequeños pueblos puede ponerse en práctica.
Por ejemplo, Soraia Amorim, una periodista ciudadana de 22 años,
escribió una historia sobre una cantidad de doctores que está en la
nómina municipal según datos del gobierno federal. Sin embargo,
descubrió que la cifra oficial no se correspondía con la situación en el
pueblo. Para escribir esta pieza, Soraia tuvo acceso a datos de salud,
que están disponibles online en http://bit.ly/tabnet-datasus[el sitio del SUS] (Sistema Único de
Saúde,un programa federal que provee ayuda médica gratuita a la población
brasileña. Según los datos de US, Januária debiera tener 71 doctores en
varias especialidades de salud.

El número de doctores indicado por los datos de SUS no se correspondía
con lo que Soraia sabía acerca de los doctores de la zona: los
residentes siempre se quejaban de la falta de doctores y algunos
pacientes tenían que viajar a pueblos vecinos para ver un profesional.
Más tarde entrevistó a una mujer que había estado recientemente en un
accidente de motocicleta, y no pudo conseguir ayuda médica en el
hospital de Januária porque no había ningún doctor disponible. También
habló con el secretario de Salud del pueblo, que reconoció que había
menos doctores en el pueblo de lo que indicaba la cifra publicada por el
SUS.

Estas conclusiones iniciales plantean muchos interrogantes respecto de
los motivos de estas diferencias entre la información oficial publicada
online, y la realidad del pueblo. Uno de ellos es que los datos
federales pueden estar equivocados, lo que significaría que hay una
importante falta de información de salud en Brasil. Otra posibilidad
puede ser que Januária está reportando incorrectamente la información al
SUS. Ambas posibilidades debieran llevar a una investigación más
profunda para encontrar la respuesta definitiva. Sin embargo, la
historia de Soria es una parte importante de esta cadena porque destaca
una inconsistencia y puede también alentar a otros a analizar esta
cuestión con más detenimiento.

“Yo antes vivía en el campo y terminé la secundaria con mucha
dificultad”, dice Soraia. “Cuando la gente me preguntaba qué quería
hacer de mi vida, siempre dije que quería ser periodista. Pero imaginaba
que era casi imposible debido al mundo en el que vivía”. Luego de
participar en la capacitación de Amigos de Januária, Soraia cree que el
acceso a datos es una herramienta importante para cambiar la realidad de
su pueblo. “Me siento capaz de ayudar a cambiar mi pueblo, mi país, el
mundo”, agrega.

Otro periodista ciudadano del proyecto es Alyson Montiériton, de 20
años, que también usó datos para un artículo. Fue durante la primera
clase del proyecto, cuando los periodistas ciudadanos caminaron por la
ciudad en busca de temas que pudieran convertirse en historias, que
Alysson decidió escribir sobre un semáforo roto ubicado en una
intersección muy importante, que había permanecido en ese estado desde
el comienzo del año. Luego de aprender a conseguir datos en Internet,
buscó la cantidad de vehículos que existe en el pueblo y la cantidad de
impuestos que pagan los dueños de autos. Escribió:

____
La situación en Januária empeora debido al alto número de vehículos en
el pueblo. Según el IBGE (el instituto de investigaciones estadísticas
más importante de Brasil), Januária tenía 13771 vehículos (entre ellos
7979 motos) en 2010… Los residentes del pueblo creen que la demora en
arreglar el semáforo no es resultado de la falta de recursos. Según el
Secretario del Tesoro del estado de Minas Gerais, el pueblo recibió
470.000 reales en impuestos sobre vehículos en 2010.
____

Teniendo acceso a los datos, Alysson pudo mostrar que Januária tiene
muchos vehículos (casi 1 por cada 5 residentes) y que un semáforo roto
podía poner en peligro a mucha gente. Lo que es más, pudo decirle a su
público la cantidad de fondos recibidos por el pueblo de impuestos
pagados por dueños de vehículos y basado en ello cuestionar si este
dinero no sería suficiente para reparar el semáforo garantizando
condiciones de seguridad a conductores y peatones.

Si bien las 2 historias escritas por Soraia y Alysson son muy simples,
muestran que los datos pueden ser usados por cronistas ciudadanos. No se
necesita estar en una gran redacción con muchos especialistas para usar
datos en sus artículos. Luego de 12 talleres, Soraia y Alysson, ninguno
de los cuales ha estudiado periodismo, pudieron trabajar en historias
basadas en datos y escribir piezas interesantes sobre su situación
local. Además sus artículos muestran que los datos mismos pueden ser
útiles incluso a escala pequeña. Dicho de otro modo también hay
información valiosa en conjuntos de datos y tablas pequeñas, no solo en
bases de datos inmensas.

&mdash; _Amanda Rossi, Friends of Januária_


=== El gran cuadro de resultados electorales

Los resultados electorales ofrecen grandes oportunidades para contar
historias de forma visual para cualquier organización de noticias, pero
durante años esta fue para nosotros una oportunidad perdida. En 2008 con
los diseñadores gráficos nos propusimos cambiar eso.

Queríamos encontrar una manera de desplegar resultados que contara una
historia y que no se viera como simplemente una mezcla de cifras en una
tabla o mapa. 
En anteriores elecciones eso es exactamente http://nyti.ms/senate-1[lo] http://nyti.ms/senate-2[que] http://nyti.ms/senate-3[hicimos].

No es que una gran bolsa de números –lo que llamo el “modelo CNN” de
tablas, tablas y más tablas- tenga algo de malo necesariamente. Funciona
porque da al lector lo que quiere saber: quién ganó.

Y es peligroso meterse con algo que no está roto. Al hacer algo
radicalmente diferente y alejarnos de lo que la gente espera podríamos
haber hecho más confusas las cosas.

Por fin, fue Shan Carter de la mesa de diseño el que dio la respuesta
adecuada, lo que terminamos llamando el “gran cuadro”. Cuando vi los
bosquejos por primera vez, fue literalmente una cachetada a la cara.

Era exactamente lo que había que hacer.

[[FIG0326]]
.El gran cuadro de resultados electorales (New York Times)
image::figs/incoming/03-ZZ-ZZ.png[float="none"]

¿Qué es lo que hace de esto una gran pieza de periodismo visual? Por
empezar, la mirada del lector es atraída inmediatamente a la gran barra
que muestra los votos del colegio electoral arriba, lo que en el
contexto periodístico podríamos llamar el _copete._Le dice al lector
exactamente lo que quiere saber y lo hace de modo rápido, simple y sin
ruido visual.

A continuación el lector es atraído al agrupamiento de estados en 5
columnas más abajo, organizado de acuerdo a la probabilidad que el Times
asignaba a que un estado dado se inclinara por uno u otro candidato. En
la columna del medio está lo que en el contexto periodístico podríamos
llamar nuestro _gráfico central_, donde explicamos por qué Obama ganó.
El interactivo lo deja totalmente claro: Obama se quedó con los estados
que se preveía y 4 de los 5 más disputados.

++++
<?dbfo-need height="1in"?>
++++

Para mi esta construcción en 5 columnas es un ejemplo de cómo el
periodismo visual difiere de otras formas de diseño. Idealmente una gran
pieza de periodismo visual será tanto hermosa como informativa. Pero
cuando tiene que decidir entre la historia y la estética, el periodista
debe volcarse para el lado de la historia. Aunque este diseño puede no
ser la manera en que un diseñador puro podría preferir presentar los
datos, presenta la historia muy, pero muy bien.

Y finalmente, como cualquier buen recurso interactivo de la red, este
invita al lector a profundizar más. Hay detalles como porcentajes de
votos, estado por estado, informes de la cantidad de votos electorales y
porcentajes deliberadamente colocados en un segundo plano para no
competir con lo principal de la historia.

Todo esto hace que el “gran cuadro” sea una gran pieza de periodismo
visual que hace un mapa casi perfecto siguiendo el esquema probado de la
pirámide invertida.

&mdash; _Aron Pilhofer, New York Times_

=== Consulta sobre el precio del agua

Desde marzo de 2011, la información sobre el agua de la canilla en toda
Francia se obtiene a través de un experimento de consulta a la
población. En solo 4 meses, mas de 5000 personas hartas del control
corporativo del mercado de agua se tomaron el tiempo de buscar su
factura, escanearla y cargarla en http://www.prixdeleau.fr/[el proyecto Prix de l’Eau] (“precio del
agua”);
El resultado es una investigación sin precedentes que reunió técnicos,
ONG y medios tradicionales para mejorar la transparencia en torno de
proyectos de agua.

[[FIG0327]]
.El precio del agua (Fundación France Liberté)
image::figs/incoming/03-WW.jpg[float="none"]

El mercado de servicios de agua consiste en más de 10.000 clientes
(ciudades que compran agua para distribuir a sus contribuyentes) y sólo
un puñado de compañías. La relación de fuerzas en este oligopolio está
distorsionado en favor de las corporaciones, que en algunos casos cobran
precios distintos a pueblos vecinos.

La ONG francesa France Libertés ha estado tratando con cuestiones de
agua en todo el mundo en los últimos 25 años. Ahora se concentra en
mejorar la transparencia del mercado francés y en dar poder a ciudadanos
y alcaldes que negocian acuerdos de servicios de agua. El gobierno
francés decidió enfrentar el problema hace 2 años con un censo nacional
del precio y la calidad el agua. Hasta ahora sólo se ha recogido el 3%
de los datos. Para ir más rápido, http://www.france-libertes.org/[France Libertés]
quería involucrar ciudadanos directamente.

++++
<?dbfo-need height="2in"?>
++++

Junto con el equipo OWNI diseñé una interfaz para la consulta en la que
los usuarios estudiaban su factura de agua e ingresaban el precio que
pagaban por el agua de la canilla en http://www.prixdeleau.fr/[prixdeleau.fr/].
En los últimos 4 meses, 8500 se inscribieron y sean cargado y validado
más de 5000 facturas.

Si bien esto no permite una evaluación perfecta de la situación del
mercado, le mostró a los interesados, tales como los entes de
supervisión del agua, que había una preocupación genuina, a nivel
popular, por el precio del agua corriente. Al principio eran escépticos
respecto de la transparencia, pero cambiaron de idea en el curso de la
operación, sumándose progresivamente a France Libertés en su lucha
contra la opacidad y la mala praxis corporativa. ¿Qué pueden aprender de
esto las organizaciones de medios?

Asociarse con ONG::

Las ONG necesitan gran cantidad de datos para diseñar trabajos de
política. Estarán más dispuestas a pagar por una operación e recolección
de datos que un ejecutivo de diario.

Los usuarios pueden aportar datos en crudo::

Las consultas funcionan del mejor modo cuando los usuarios cumplen una
tarea de recolección de datos o refinado de datos.

Pedir la fuente de la información::

Evaluamos si pedir a los usuarios una copia de la factura original,
pensando que disuadiría a algunos de ellos (especialmente dado que
nuestro público era mayor en promedio). Si bien pudo haber sido una
traba para algunos, aumentó la credibilidad de los datos.

Crear un mecanismo de validación::

Diseñamos un sistema de puntaje y un mecanismo http://www.prixdeleau.fr/valider[de revisión por los pares]
para controlar los aportes de los usuarios. Esto demostró ser demasiado
engorroso para los usuarios, que tenían pocos incentivos para hacer
visitas repetidas al sitio. Pero fue utilizado por el equipo de France
Libertés, cuyos empleados, alrededor de 10, se sintieron motivados por
el sistema de puntaje.

Mantenerlo simple::

Creamos un mecanismo de correo automatizado de modo que los usuarios
pudieran presentar un pedido de acceso a la información respecto de
precios del agua con solo unos pocos clics. Aunque innovador y bien
diseñado, este recurso no generó un número sustancial de pedidos (solo
100 fueron enviados).

Defina su público::

France Libertés se asoció con la revista dedicada a los derechos de los
consumidores _60 Millions de Consommateurs_, que lograron una gran
participación de su comunidad. Fue la unión prefecta para esta
operación.

Elija cuidadosamente sus indicadores claves de desempeño::

El proyecto tuvo solo 45.000 visitantes en 4 meses, equivalente a 15
minutos de tráfico en http://www.nytimes.com/[nytimes.com].
Lo importante es que 1 de cada 5 se inscribió y 1 de cada 10 se tomó el
tiempo de escanear y subir su factura.

&mdash; _Nicolas Kayser-Bril, Journalism++_


